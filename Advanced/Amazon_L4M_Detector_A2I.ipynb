{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Amazon Lookout for Metrics with Amazon Augmented AI (A2I)\n",
    "\n",
    "Amazon Lookout for Metrics can help you identify anomalies within your data metrics that you gather on a periodic basis. In this notebook we show how to pass the anomalous results for human review and use the feedback for improving model accuracy.  \n",
    "\n",
    "We are extending the example usecase for Amazon Lookout for Metrics that was discussed in an [earlier blog](https://aws.amazon.com/blogs/machine-learning/introducing-amazon-lookout-for-metrics-an-anomaly-detection-service-to-proactively-monitor-the-health-of-your-business/) and integrating it with Amazon A2I.\n",
    "\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Create a Detector and configure its detection properties.\n",
    "2. Create a Metric Set:\n",
    "    1. Provide the location of your source data and the IAM permissions needed to access it. \n",
    "    1. Define the Metrics that you want to investigate.\n",
    "    1. Attach the dataset to your Detector.\n",
    "3. Activate the Detector.\n",
    "4. Pass the detected outliers to a human work team for review.\n",
    "6. Provide feedback on the outliers to improve predictor model's accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.0. Prerequisites\n",
    "\n",
    "1. The code uses Python 3.7. Please use the Python 3 (Data Science) kernel for this notebook.\n",
    "2. If you need thsi Notebook to create an IAM role for Lookout For Metrics, SageMaker will need permissions to create the IAM role. You can find teh IAM role used by SageMaker Studio in the [SageMaker Studio Control Panel](https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-quick-start.html). \n",
    "\n",
    "Note: It is OK to encounter the following error in the output of next cell.\n",
    "<br/><span style=\"color:tomato\">ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "awscli 1.19.47 requires botocore==1.20.47, but you have botocore 1.20.91 which is incompatible.\n",
    "awscli 1.19.47 requires s3transfer<0.4.0,>=0.3.0, but you have s3transfer 0.4.2 which is incompatible.\n",
    "aiobotocore 1.2.2 requires botocore<1.19.53,>=1.19.52, but you have botocore 1.20.91 which is incompatible.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.1.3)\n",
      "Collecting pip\n",
      "  Downloading pip-21.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 7.3 MB/s eta 0:00:01     |█                               | 51 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1.3\n",
      "    Uninstalling pip-21.1.3:\n",
      "      Successfully uninstalled pip-21.1.3\n",
      "Successfully installed pip-21.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.7/site-packages (1.20.107)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.21.10-py3-none-any.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore) (1.26.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.107\n",
      "    Uninstalling botocore-1.20.107:\n",
      "      Successfully uninstalled botocore-1.20.107\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.17.107 requires botocore<1.21.0,>=1.20.107, but you have botocore 1.21.10 which is incompatible.\n",
      "awscli 1.19.47 requires botocore==1.20.47, but you have botocore 1.21.10 which is incompatible.\n",
      "awscli 1.19.47 requires s3transfer<0.4.0,>=0.3.0, but you have s3transfer 0.4.2 which is incompatible.\n",
      "aiobotocore 1.2.2 requires botocore<1.19.53,>=1.19.52, but you have botocore 1.21.10 which is incompatible.\u001b[0m\n",
      "Successfully installed botocore-1.21.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (1.17.107)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.18.10-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 684 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.10 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.21.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.10->boto3) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.10->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.10->boto3) (1.16.0)\n",
      "Installing collected packages: s3transfer, boto3\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.4.2\n",
      "    Uninstalling s3transfer-0.4.2:\n",
      "      Successfully uninstalled s3transfer-0.4.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.107\n",
      "    Uninstalling boto3-1.17.107:\n",
      "      Successfully uninstalled boto3-1.17.107\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.19.47 requires botocore==1.20.47, but you have botocore 1.21.10 which is incompatible.\n",
      "awscli 1.19.47 requires s3transfer<0.4.0,>=0.3.0, but you have s3transfer 0.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.18.10 s3transfer-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.7/site-packages (1.21.10)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore) (1.26.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "## IGNORE ANY ERRORS ##\n",
    "!pip install --upgrade pip\n",
    "!pip install botocore --upgrade\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import datetime\n",
    "import pprint\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "import texttable as tt\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import botocore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.1. Create S3 bucket\n",
    "\n",
    "Create an S3 bucket where we will upload data for Amazon Lookout for Metrics. The bucket is created only if it does not already exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: 095351214964-us-west-2-lookoutmetrics-lab already exists.\n"
     ]
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "bucket_name = account_id + \"-\" + region + \"-lookoutmetrics-lab\"\n",
    "\n",
    "\n",
    "# Use SageMaker's default S3 bucket, where training output will be stored. \n",
    "#bucket_name = session.default_bucket()  # Custom bucket name can be used.\n",
    "#print (\"S3 Bucket Name: \" + bucket_name)\n",
    "\n",
    "#Create the bucket of it does not exist\n",
    "s3 = boto3.resource('s3')\n",
    "exists = True\n",
    "if s3.Bucket(bucket_name).creation_date is None:\n",
    "    exists = False\n",
    "\n",
    "if not exists:\n",
    "    try:\n",
    "        if  region == 'us-east-1':\n",
    "          s3.create_bucket(Bucket=bucket_name)\n",
    "        else: \n",
    "          s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': region })\n",
    "        print('S3 bucket {} created successfully'.format(bucket_name))\n",
    "    except Exception as e:\n",
    "        print('S3 error: ', e)\n",
    "else: \n",
    "    print(\"S3 Bucket: {} already exists.\".format(bucket_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2. Configure IAM Role\n",
    "\n",
    "Create an IAM role that will be assumed by Amazon Lookout for Metrics service and will allow it to communicate with S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role L4M_iam_role already existed\n",
      "arn:aws:iam::095351214964:role/L4M_iam_role\n"
     ]
    }
   ],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"L4M_iam_role\"\n",
    "\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"lookoutmetrics.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_role_response = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "    )\n",
    "    role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "    \n",
    "    print(\"Created %s\" % role_name)\n",
    "    print(\"Attaching policies\")\n",
    "\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    )\n",
    "    print(\"Waiting for a minute to allow IAM role policy attachment to propagate\")\n",
    "    time.sleep(60)\n",
    "\n",
    "\n",
    "except iam.exceptions.EntityAlreadyExistsException:\n",
    "    print(\"Role %s already existed\" % role_name )\n",
    "    role_arn = boto3.resource('iam').Role(role_name).arn\n",
    "\n",
    "\n",
    "#iam.attach_role_policy(\n",
    "#    RoleName = role_name,\n",
    "#    PolicyArn = \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\"\n",
    "#)\n",
    "\n",
    "print(role_arn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.0. Generate synthetic data\n",
    "\n",
    "We will generate data both for training the detector and for prediction of anomalies. In this example the detector will be used in continuous mode to detect anomalies. Starting from the current date, we generate data for a default period of 6 months in the past and 3 days in the future. The period is configurable through constants defined in the next cell.\n",
    "\n",
    "The historical data is used for training the model, while the future data will be used for predicting anomalies on an ongoing basis.\n",
    "\n",
    "* Historical data will be created as a csv file called \"./data/ecommerce/backtest/input.csv\"\n",
    "* Hourly data files will be stored in folder, \"./data/ecommerce/live/{yyyyMMdd}/{HH:mm}/{yyyyMMdd_HH:mm:ss}.csv\"\n",
    "* Complete data along with the anomaly labels is available in \"./data/ecommerce/label.csv\"\n",
    "\n",
    "The data in local folders is replaced based on current date, on every execution of this section.\n",
    "\n",
    "*Note: Synthetic data generation may take about 4 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local folders for data\n",
    "DATASET_NAME = \"ecommerce\"\n",
    "DIR_PATH = './data'\n",
    "\n",
    "#######################################################################\n",
    "# Set constants for the duration of historical and future periods for data generation.\n",
    "NUM_MONTHS_HISTORICAL_DATA = 6\n",
    "NUM_DAYS_FUTURE_DATA = 3\n",
    "\n",
    "# Metrics will be received at the top of every hour.\n",
    "FREQUENCY = \"PT1H\" # one of 'P1D', 'PT1H', 'PT10M' and 'PT5M'\n",
    "#######################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1. Generate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 64.3 ms, total: 2.06 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "dimensions = { \"platform\" : [ \"pc_web\", \"mobile_web\", \"mobile_app\" ], \"marketplace\" : [ \"us\", \"uk\", \"de\", \"fr\", \"es\", \"it\", \"jp\" ] }\n",
    "metrics = [ \"views\", \"revenue\" ]\n",
    "\n",
    "metric_period = \"1H\"\n",
    "\n",
    "daily_peak_size_range = ( 200, 400 )\n",
    "daily_peak_time = ( 12 * 60, 21 * 60 )\n",
    "daily_offset_range = ( 100, 200 )\n",
    "\n",
    "random_factor_size_range = (2, 10)\n",
    "\n",
    "anomaly_size_range = ( 100, 600 )\n",
    "anomaly_length_range = ( 1, 5 * 60 )\n",
    "anomaly_possibility = 0.005\n",
    "#anomaly_possibility = 0.2\n",
    "\n",
    "introduce_metric_from_upstream = [\n",
    "    lambda x : max( int(x), 0 ),    # sin curve -> views \n",
    "    lambda x : x * 0.3,             # views -> revenue\n",
    "]\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "class DailyPattern:\n",
    "    \n",
    "    def __init__( self ):\n",
    "        self.peak_size = random.uniform( *daily_peak_size_range )\n",
    "        self.peak_time = random.uniform( *daily_peak_time )\n",
    "        self.offset = random.uniform( *daily_offset_range )\n",
    "    \n",
    "    def get( self, t ):\n",
    "        \n",
    "        minutes_in_day = t.hour * 60 + t.minute\n",
    "        \n",
    "        factor1 = math.cos( (( minutes_in_day - self.peak_time ) / ( 24 * 60 )) * 2 * math.pi ) * self.peak_size + self.peak_size + self.offset\n",
    "        \n",
    "        return factor1\n",
    "\n",
    "class RandomFactor:\n",
    "    \n",
    "    def __init__( self ):\n",
    "        self.size = random.uniform( *random_factor_size_range )\n",
    "\n",
    "    def get(self):\n",
    "        return random.uniform( -self.size, self.size )\n",
    "\n",
    "\n",
    "class Anomaly:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.remaining_time = random.randint( *anomaly_length_range )\n",
    "        self.offset = random.uniform( *anomaly_size_range ) * (random.randint(0,1)*2-1)\n",
    "        #print( self.offset )\n",
    "\n",
    "    def proceed_time(self):\n",
    "        self.remaining_time -= pd.to_timedelta(metric_period).seconds / 60\n",
    "        return self.remaining_time <= 0\n",
    "\n",
    "    def get(self):\n",
    "        return self.offset\n",
    "\n",
    "class Item:\n",
    "\n",
    "    def __init__( self, dimension ):\n",
    "        \n",
    "        #print( dimension )\n",
    "        \n",
    "        self.dimension = dimension\n",
    "        \n",
    "        self.daily_pattern = DailyPattern()\n",
    "        self.random_factor = RandomFactor()\n",
    "        self.anomaly = None\n",
    "    \n",
    "    def get( self, t ):\n",
    "    \n",
    "        if random.random() < anomaly_possibility:\n",
    "            self.anomaly = Anomaly()\n",
    "        \n",
    "        value = self.daily_pattern.get(t)\n",
    "        \n",
    "        value += self.random_factor.get()\n",
    "\n",
    "        is_anomaly = bool(self.anomaly)\n",
    "        if self.anomaly:\n",
    "            value += self.anomaly.get()\n",
    "            if self.anomaly.proceed_time():\n",
    "                self.anomaly = None\n",
    "        \n",
    "        metric_values = []\n",
    "        for i, metric in enumerate(metrics):\n",
    "            value = introduce_metric_from_upstream[i](value)\n",
    "            metric_values.append(value)\n",
    "        \n",
    "        #if (is_anomaly):\n",
    "            #print (metric_values, is_anomaly)\n",
    "        \n",
    "        return metric_values, is_anomaly\n",
    "\n",
    "\n",
    "def synthesize(period):\n",
    "\n",
    "    # create item list\n",
    "    item_list = []\n",
    "    for dimension_values in itertools.product( *dimensions.values() ):\n",
    "        item = Item( dict( zip( dimensions.keys(), dimension_values ) ) )\n",
    "        item_list.append(item)\n",
    "    \n",
    "    # itereate and prepare data    \n",
    "    dimension_values_list = []\n",
    "    for i in range( len(dimensions) ):\n",
    "        dimension_values_list.append([])\n",
    "\n",
    "    timestamp_list = []\n",
    "\n",
    "    metric_values_list = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        metric_values_list.append([])\n",
    "\n",
    "    labels_list = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        labels_list.append([])\n",
    "    \n",
    "    t = period[0]\n",
    "    while t<period[1]:\n",
    "        \n",
    "        #print(t)\n",
    "\n",
    "        for item in item_list:\n",
    "            \n",
    "            for i, d in enumerate(item.dimension.values()):\n",
    "                #print(i,d)\n",
    "                dimension_values_list[i].append(d)\n",
    "            \n",
    "            timestamp_list.append(t)\n",
    "            \n",
    "            metric_values, is_anomaly = item.get(t)\n",
    "            for i, metric_value in enumerate(metric_values):\n",
    "                metric_values_list[i].append(metric_value)\n",
    "                labels_list[i].append( int(is_anomaly) )\n",
    "\n",
    "        t += pd.to_timedelta(metric_period)\n",
    "        \n",
    "    # convert to DataFrame\n",
    "    data = {}\n",
    "    for dimension_name, dimension_values in zip( dimensions.keys(), dimension_values_list ):\n",
    "        data[dimension_name] = dimension_values\n",
    "    data[\"timestamp\"] = timestamp_list\n",
    "    for metric_name, metric_values in zip( metrics, metric_values_list ):\n",
    "        data[metric_name] = metric_values\n",
    "    for metric_name, labels in zip( metrics, labels_list ):\n",
    "        data[metric_name + \"_label\"] = labels    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def splot_into_intervals( df, output_dirname ):\n",
    "\n",
    "    #print(df.head())\n",
    "    df[\"views\"] *= random.uniform(0.1, 2.0)\n",
    "    df[\"views\"] = df[\"views\"].apply(lambda x: int(x))\n",
    "\n",
    "    df[\"revenue\"] *= random.uniform(0.1, 2.0)\n",
    "    df[\"revenue\"] = df[\"revenue\"].apply(lambda x: round(x, 2))\n",
    "    #print(df.head())\n",
    "    \n",
    "    for timestamp, df_single_timestamp in df.groupby(\"timestamp\"):        \n",
    "        dirname = os.path.join( output_dirname, timestamp.strftime( \"%Y%m%d/%H%M\" ) )\n",
    "        filename = os.path.join( dirname, timestamp.strftime(\"%Y%m%d_%H%M%S.csv\") )\n",
    "\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs( dirname )\n",
    "        \n",
    "        df_single_timestamp.to_csv( filename, index=False, date_format=\"%Y-%m-%d %H:%M:%S\" )\n",
    "\n",
    "\n",
    "def generate_data(period, data_type):\n",
    "    \n",
    "    df_full = synthesize(period)\n",
    "    \n",
    "    # Create new ones:\n",
    "    if not os.path.exists(\"./data/{}/{}\".format(DATASET_NAME,data_type)):\n",
    "        os.makedirs(\"./data/{}/{}\".format(DATASET_NAME,data_type))\n",
    "\n",
    "    df_full.to_csv( \"./data/%s/label.csv\" % DATASET_NAME, index=False )\n",
    "    label_colunn_names = [ metric_name + \"_label\" for metric_name in metrics ]\n",
    "    df_input = df_full.drop( columns = label_colunn_names )\n",
    "    \n",
    "    if (data_type == \"backtest\"):\n",
    "        df_input.to_csv( \"./data/{}/backtest/input.csv\".format(DATASET_NAME), index=False )\n",
    "    else:\n",
    "        splot_into_intervals( df_input, \"./data/{}/live\".format(DATASET_NAME))\n",
    "\n",
    "\n",
    "# Get rid of old files:\n",
    "try:\n",
    "    shutil.rmtree(DIR_PATH, ignore_errors=False, onerror=None)\n",
    "except:\n",
    "    print('Error while deleting directory')\n",
    "\n",
    "start = date.today() + relativedelta(months =- NUM_MONTHS_HISTORICAL_DATA)\n",
    "end = date.today()\n",
    "period = (datetime.datetime(start.year, start.month, start.day), datetime.datetime(end.year, end.month, end.day))\n",
    "\n",
    "generate_data(period, \"backtest\")\n",
    "\n",
    "start = date.today()\n",
    "end = date.today()  + relativedelta(days =+ NUM_DAYS_FUTURE_DATA)\n",
    "period = (datetime.datetime(start.year, start.month, start.day), datetime.datetime(end.year, end.month, end.day))\n",
    "\n",
    "generate_data(period, \"live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>views</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pc_web</td>\n",
       "      <td>us</td>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>298</td>\n",
       "      <td>89.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc_web</td>\n",
       "      <td>uk</td>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>476</td>\n",
       "      <td>142.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pc_web</td>\n",
       "      <td>de</td>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>152</td>\n",
       "      <td>45.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pc_web</td>\n",
       "      <td>fr</td>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>405</td>\n",
       "      <td>121.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pc_web</td>\n",
       "      <td>es</td>\n",
       "      <td>2021-01-30 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform marketplace            timestamp  views  revenue\n",
       "0   pc_web          us  2021-01-30 00:00:00    298     89.4\n",
       "1   pc_web          uk  2021-01-30 00:00:00    476    142.8\n",
       "2   pc_web          de  2021-01-30 00:00:00    152     45.6\n",
       "3   pc_web          fr  2021-01-30 00:00:00    405    121.5\n",
       "4   pc_web          es  2021-01-30 00:00:00    113     33.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "backtest_df = pd.read_csv('data/ecommerce/backtest/input.csv')\n",
    "backtest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2. Save data to S3 bucket\n",
    "\n",
    "Save the data into the s3 bucket created earlier.\n",
    "\n",
    "*Will take about 1 min 30 sec.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 ms, sys: 12.5 ms, total: 39.4 ms\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!aws s3 sync {DIR_PATH}/{DATASET_NAME}/ s3://{bucket_name}/{DATASET_NAME}/ --quiet --delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0. Create Lookout for Metrics Detector\n",
    "\n",
    "The `Detector` is a machine learning model that detects outliers in the metrics. The detector is automatically trained with the machine learning algorithm that best fits your data and use case. You can optionally provide your historical data for training, if you have any. Otherwise, get started with real-time data, and Amazon Lookout for Metrics will learn on-the-go. For this example we provide 6 months of historical data.\n",
    "\n",
    "You specify the Amazon S3 location that Amazon Lookout for Metrics should continuously monitor for new data, and your detector analyzes your data and returns information about the outliers that it detected. When you create a `Detector`, you also specify a `detecting domain` and an `outlier detection frequency`. \n",
    "\n",
    "The `anomaly detection frequency` specifies how frequently the detector should wake-up and look for new data, run analysis and alert you with any interesting findings. For this example, the detector will look for anomalies at the top of every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomaly Detector ARN:\n",
      "arn:aws:lookoutmetrics:us-west-2:095351214964:AnomalyDetector:ecommerce-continuous-detector-demo-0730\n"
     ]
    }
   ],
   "source": [
    "L4M = boto3.client( \"lookoutmetrics\")\n",
    "\n",
    "ecom_anomaly_detector_name = \"ecommerce-continuous-detector-demo-0730\"\n",
    "ecom_anomaly_detector_arn = ''\n",
    "\n",
    "detector_list =[]\n",
    "\n",
    "# Check if the eCommerce detector already exists \n",
    "list_anomaly_detectors_response = L4M.list_anomaly_detectors(MaxResults=100)\n",
    "\n",
    "anomaly_detectors_list = list_anomaly_detectors_response['AnomalyDetectorSummaryList']\n",
    "\n",
    "#print(\"Anomaly detectors list:\\n {}\".format(anomaly_detectors_list))\n",
    "\n",
    "for anomaly_detector in anomaly_detectors_list:\n",
    "    \n",
    "    #print('anomaly_detector: {}'.format(anomaly_detector))\n",
    "\n",
    "    if anomaly_detector['AnomalyDetectorName'] == ecom_anomaly_detector_name:\n",
    "        # the detector for ecommerce example exists. Get its ARN\n",
    "        ecom_anomaly_detector_arn = anomaly_detector['AnomalyDetectorArn']\n",
    "        break\n",
    "\n",
    "if len(ecom_anomaly_detector_arn) == 0:\n",
    "    # Detector for ecommerce example does not exists. Create the anomaly detector.\n",
    "    create_anomaly_detector_response = L4M.create_anomaly_detector( \n",
    "        AnomalyDetectorName = ecom_anomaly_detector_name,\n",
    "        AnomalyDetectorDescription = \"Anomaly detection on a sample ecommerce dataset.\",\n",
    "        AnomalyDetectorConfig = {\n",
    "            \"AnomalyDetectorFrequency\" : FREQUENCY,   \n",
    "        },\n",
    "    )\n",
    "\n",
    "    ecom_anomaly_detector_arn = create_anomaly_detector_response[\"AnomalyDetectorArn\"]\n",
    "    \n",
    "print('\\nAnomaly Detector ARN:\\n{}'.format(ecom_anomaly_detector_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1. Define Metrics\n",
    "\n",
    "### Measures and Dimensions\n",
    "\n",
    "`Measures` are variables or key performance indicators on which customers want to detect outliers and `Dimensions` are meta-data that represent categorical information about the measures. \n",
    "\n",
    "In this E-commerce example, views and revenue are our measures, and platform and marketplace are our dimensions. Customers may want to monitor their data for anomalies in number of views or revenue for every platform, marketplace, and combination of both. You can designate up to five measures and five dimensions per dataset.\n",
    "\n",
    "### Metrics \n",
    "\n",
    "After creating a detector, and mapping your measures and dimensions, Amazon Lookout for Metrics will analyze each combination of these measures and dimensions. For the above example, we have of 7 unique values (us, jp, de, etc.) for marketplace and 3 unique values (mobile web, mobile app, pc web) for platform for a total of 21 unique combinations. Each unique combination of measures with the dimension values (e.g. us/mobile app/revenue) is a time series `metric`. In this case, we have 21 dimensions and 2 measures for a total of 42 time-series `metrics`. \n",
    "\n",
    "Amazon Lookout for Metrics detects anomalies at the most granular level so you are able to pin-point any unexpected behavior in your data.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "Measures, dimensions and metrics map to `datasets`, which also contain the Amazon S3 locations of your source data, an IAM role that has both read and write permissions to those Amazon S3 locations, and the rate at which data should be ingested from the source location (the upload frequency and data ingestion delay).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the metric set for this example exists\n",
    "\n",
    "ecom_metric_set_name = \"ecommerce-metric-set\"\n",
    "ecom_metric_set_arn = ''\n",
    "\n",
    "metric_sets_list =[]\n",
    "\n",
    "\n",
    "list_metric_sets_response = L4M.list_metric_sets(\n",
    "        AnomalyDetectorArn=ecom_anomaly_detector_arn,\n",
    "        MaxResults=100)\n",
    "\n",
    "metric_sets_list = list_metric_sets_response['MetricSetSummaryList']\n",
    "#print(\"Anomaly detectors list:\\n {}\".format(metric_sets_list))\n",
    "\n",
    "for metric_set in metric_sets_list:\n",
    "    \n",
    "    #print('metric_set: {}'.format(metric_set))\n",
    "\n",
    "    if metric_set['MetricSetName'] == ecom_metric_set_name:\n",
    "        \n",
    "        ecom_metric_set_arn = metric_set['MetricSetArn']\n",
    "        print(\"\\nMetric Set ARN:\\n{}\".format(ecom_metric_set_arn))\n",
    "        \n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric Set ARN: arn:aws:lookoutmetrics:us-west-2:095351214964:MetricSet/ecommerce-continuous-detector-demo-0730/ecommerce-metric-set\n"
     ]
    }
   ],
   "source": [
    "# If metric set for this example is not found, create it.\n",
    "if len(ecom_metric_set_arn) == 0:\n",
    "    s3_path_format = 's3://'+ bucket_name + '/ecommerce/live/{{yyyyMMdd}}/{{HHmm}}'\n",
    "    s3_historical_path_prefix = 's3://'+ bucket_name + '/ecommerce/backtest/input.csv'\n",
    "\n",
    "\n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\": ecom_anomaly_detector_arn,\n",
    "        \"MetricSetName\" : ecom_metric_set_name,\n",
    "        \"MetricList\" : [\n",
    "            {\n",
    "                \"MetricName\" : \"views\",\n",
    "                \"AggregationFunction\" : \"SUM\",\n",
    "            },\n",
    "            {\n",
    "                \"MetricName\" : \"revenue\",\n",
    "                \"AggregationFunction\" : \"SUM\",\n",
    "            },\n",
    "        ],\n",
    "\n",
    "        \"DimensionList\" : [ \"platform\", \"marketplace\" ],\n",
    "\n",
    "        \"TimestampColumn\" : {\n",
    "            \"ColumnName\" : \"timestamp\",\n",
    "            \"ColumnFormat\" : \"yyyy-MM-dd HH:mm:ss\",\n",
    "        },\n",
    "\n",
    "        #\"Delay\" : 120, # seconds the detector will wait before attempting to read latest data per current time and detection frequency below\n",
    "        \"MetricSetFrequency\" : FREQUENCY,\n",
    "\n",
    "        \"MetricSource\" : {\n",
    "            \"S3SourceConfig\": {\n",
    "                \"RoleArn\" : role_arn,\n",
    "                \"HistoricalDataPathList\": [\n",
    "                    s3_historical_path_prefix,\n",
    "                ],\n",
    "                \"TemplatedPathList\": [\n",
    "                    s3_path_format,\n",
    "                ],\n",
    "\n",
    "                \"FileFormatDescriptor\" : {\n",
    "                    \"CsvFormatDescriptor\" : {\n",
    "                        \"FileCompression\" : \"NONE\",\n",
    "                        \"Charset\" : \"UTF-8\",\n",
    "                        \"ContainsHeader\" : True,\n",
    "                        \"Delimiter\" : \",\",\n",
    "                        \"QuoteSymbol\" : '\"'\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    create_metric_set_response = L4M.create_metric_set( ** params )\n",
    "    ecom_metric_set_arn = create_metric_set_response[\"MetricSetArn\"]\n",
    "\n",
    "print(\"\\nMetric Set ARN: {}\".format(ecom_metric_set_arn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.0. Activate the Detector\n",
    "\n",
    "During activation the model is trained with historical data that was generated above and stored in the \"./data/ecommerce/backtest\" folder.\n",
    "\n",
    "*The activation process can take about 20 minutes.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activating ecommerce example Detector.\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: ACTIVATING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "Detector status: LEARNING\n",
      "CPU times: user 1.74 s, sys: 260 ms, total: 2 s\n",
      "Wall time: 1h 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get detector details\n",
    "describe_anomaly_detector_response =L4M.describe_anomaly_detector(\n",
    "    AnomalyDetectorArn=ecom_anomaly_detector_arn)\n",
    "\n",
    "#print(\"\\nEcommerce Detector details: \")\n",
    "#pprint.pprint(describe_anomaly_detector_response, width = 2)\n",
    "\n",
    "ecom_detector_status = describe_anomaly_detector_response['Status']\n",
    "\n",
    "if ecom_detector_status in [\"INACTIVE\", \"ACTIVATING\"]:\n",
    "    \n",
    "    # Activate the detector\n",
    "    if ecom_detector_status == \"INACTIVE\":\n",
    "        L4M.activate_anomaly_detector(AnomalyDetectorArn = ecom_anomaly_detector_arn)\n",
    "    \n",
    "        print(\"\\nActivating ecommerce example Detector.\")\n",
    "    \n",
    "    # Check status every 10 secs untile detector is ACTIVE\n",
    "    while (ecom_detector_status in [\"ACTIVATING\", \"INACTIVE\", \"LEARNING\"]):\n",
    "        response = L4M.describe_anomaly_detector( AnomalyDetectorArn = ecom_anomaly_detector_arn )\n",
    "        ecom_detector_status = response[\"Status\"]\n",
    "        if ecom_detector_status == \"ACTIVE\" :\n",
    "            break;\n",
    "        else: \n",
    "            time.sleep(10)\n",
    "            print(\"Detector status: {}\".format(ecom_detector_status))\n",
    "    \n",
    "elif ecom_detector_status == \"ACTIVE\":\n",
    "    print(\"\\nEcommerce example detector is Active\")\n",
    "else:\n",
    "    print(\"\\nEcommerce Detector Status: {}\".format(ecom_detector_status))\n",
    "    print(\"\\nDelete old detector in console and rerun this notebook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.0. Fetch Anomalies\n",
    "\n",
    "We have created a continuous detector that will operate on live data. It expects to receive input data every hour. We already generated some data into the future and you can find it in the \"./data/ecommerce/live\" folder. \n",
    "\n",
    "**Note:** \n",
    "*You may have to wait for the detector to run at the top of the hour to detect anomalies. So, if no anomalies are found when executing the next cell, you may want to come back later and run it again.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly group summaries:\n",
      " {'ResponseMetadata': {'RequestId': 'f68237a9-d68f-43a7-81ad-3145fc22f482', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 30 Jul 2021 19:45:52 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '621', 'connection': 'keep-alive', 'x-amzn-requestid': 'f68237a9-d68f-43a7-81ad-3145fc22f482', 'x-amz-apigw-id': 'DTKFmE5rvHcFUpQ=', 'x-amzn-trace-id': 'Root=1-610456f0-3649e4c507cacee44132452c'}, 'RetryAttempts': 0}, 'AnomalyGroupSummaryList': [{'StartTime': '2021-07-30T15:00Z[UTC]', 'EndTime': '2021-07-30T18:00Z[UTC]', 'AnomalyGroupId': '70fda132-89c3-48c8-8285-6a2b5e6ad468', 'AnomalyGroupScore': 99.79, 'PrimaryMetricName': 'revenue'}, {'StartTime': '2021-07-30T15:00Z[UTC]', 'EndTime': '2021-07-30T15:00Z[UTC]', 'AnomalyGroupId': '2ceec6c2-2f2e-4081-84e2-5884c581e66c', 'AnomalyGroupScore': 97.57, 'PrimaryMetricName': 'views'}], 'AnomalyGroupStatistics': {'EvaluationStartDate': '2021-07-16T18:00Z[UTC]', 'TotalCount': 2, 'ItemizedMetricStatsList': [{'MetricName': 'revenue', 'OccurrenceCount': 1}, {'MetricName': 'views', 'OccurrenceCount': 1}]}}\n",
      "\n",
      "type of AnomalyGroupSummaryList: <class 'list'>\n",
      "\n",
      "Anomaly group id: 70fda132-89c3-48c8-8285-6a2b5e6ad468, Anomaly group score: 99.79\n",
      "\n",
      "Anomaly group id: 2ceec6c2-2f2e-4081-84e2-5884c581e66c, Anomaly group score: 97.57\n"
     ]
    }
   ],
   "source": [
    "#ecom_anomaly_detector_arn = 'arn:aws:lookoutmetrics:us-west-2:095351214964:AnomalyDetector:my-detector'\n",
    "#ecom_anomaly_detector_name = \"my-detector\"\n",
    "\n",
    "############################\n",
    "anomaly_score_cutoff = 50\n",
    "############################\n",
    "\n",
    "anomaly_groups = []\n",
    "next_token = None\n",
    "\n",
    "while True:    \n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\" : ecom_anomaly_detector_arn,\n",
    "        \"SensitivityThreshold\" : anomaly_score_cutoff,\n",
    "        \"MaxResults\" : 100,\n",
    "    }\n",
    "\n",
    "    if next_token:\n",
    "        params[\"NextToken\"] = next_token\n",
    "\n",
    "    response = L4M.list_anomaly_group_summaries(**params )\n",
    "    \n",
    "    print(\"Anomaly group summaries:\\n {}\".format(response))\n",
    "\n",
    "    anomaly_groups += response[\"AnomalyGroupSummaryList\"]\n",
    "    print('\\ntype of AnomalyGroupSummaryList: {}'.format(type(anomaly_groups)))\n",
    "    \n",
    "    for entry in anomaly_groups:\n",
    "        print('\\nAnomaly group id: {}, Anomaly group score: {}'.format(entry['AnomalyGroupId'], entry['AnomalyGroupScore']))\n",
    "        \n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "        continue\n",
    "\n",
    "    break\n",
    "\n",
    "if len(anomaly_groups) == 0:\n",
    "    print(\"\\nAnomalies not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.1. Build a Pandas Dataframe with anomaly details to pass to human workflow \n",
    "\n",
    "Iterate over the anomaly results and build a dataframe. For each measure in an anomaly group, we fetch the list of anomalous metrics. For each anomalous dimension and its value, we get an associated system generated time series id. After human review of anomalies, we will need the time series id for each metric to when we register human feedback into Lookout Metrics to improve future prediction results.\n",
    "We save the time series id along with the timestamp and metric details into a new dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{'AnomalyGroupId': '70fda132-89c3-48c8-8285-6a2b5e6ad468',\n",
      " 'AnomalyGroupScore': 99.79,\n",
      " 'EndTime': '2021-07-30T18:00Z[UTC]',\n",
      " 'PrimaryMetricName': 'revenue',\n",
      " 'StartTime': '2021-07-30T15:00Z[UTC]'}\n",
      "data: {'tseriesid': '5ca58fe57ba9367b6fae544425f551d09896b71ad7ec932b02b160aa208d5602abb4cd05420d10cc22bbcc25b54970a9e1ed238300a23a06c2cdc62519e683c1'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': 'dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921aee424ddc6057f7289ae5aa7ca3d74ef8489a3c34dbf6303dc1328d20a65f5b1eb82e28bc6ad267e85a'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '83e8e8bc0d559d548d2ccea76f087325b26a3defa7c6d0f76ecead7c5ae21e9559b3a30134ffba469f50b5dce1c351289df016ae3b99254c1a2c79965344d886'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': 'dfd68a1948784ac73f34bc888bd1f9613b942ddd88e98863b47b6b85ff82f2bfa08dba40f1874b8561ae0cd55302f8274c1b00e353e8d217a0c6f42ac6de45be'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf112d723a00d22ccebe6510a4d314531c43e2a5709bf65fc71c6b8352446254c7aef9b30e9a515e00d7f'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a5804d8bb7603782c4a2b5f5d8a5e7d5253829df468799df5a9e367eec2d2ca3bd3f929534a7b1d91ee7e6'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb867282a0d5959afb95f421ca6b6be816506f41309262ff825b1d2c51e2966e91ba520a565d4dd00e8a0c'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f266d428d6f62d20847874912a86ef9c7c6f27d4725d20fad88601c2a77cc6cfed63f3dc1a42b06b6445'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: mobile_app\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '458bf5a14cf52cd965cb7465f17e160d4e91dc047f66f4ec0e2ab8909c71a93750fa28c7a8890b9bd0976b0694fa78f6e0ea364ae7e55e7f9c25455c0cde5cc5'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '54ea05b36b8d33633dc03c84da6f54231309b25f5bea8437594dbc6f73383dfd5e190161f9996bafb397e1dba32309778c2411cd92202bf9c528796f714eb7ea'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1600/20210730_160000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=17, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1700/20210730_170000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_web\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=18, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1800/20210730_180000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_web\n",
      "\n",
      "\n",
      "\n",
      "{'AnomalyGroupId': '2ceec6c2-2f2e-4081-84e2-5884c581e66c',\n",
      " 'AnomalyGroupScore': 97.57,\n",
      " 'EndTime': '2021-07-30T15:00Z[UTC]',\n",
      " 'PrimaryMetricName': 'views',\n",
      " 'StartTime': '2021-07-30T15:00Z[UTC]'}\n",
      "data: {'tseriesid': '5ca58fe57ba9367b6fae544425f551d09896b71ad7ec932b02b160aa208d5602abb4cd05420d10cc22bbcc25b54970a9e1ed238300a23a06c2cdc62519e683c1'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': 'dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921aee424ddc6057f7289ae5aa7ca3d74ef8489a3c34dbf6303dc1328d20a65f5b1eb82e28bc6ad267e85a'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '83e8e8bc0d559d548d2ccea76f087325b26a3defa7c6d0f76ecead7c5ae21e9559b3a30134ffba469f50b5dce1c351289df016ae3b99254c1a2c79965344d886'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': 'dfd68a1948784ac73f34bc888bd1f9613b942ddd88e98863b47b6b85ff82f2bfa08dba40f1874b8561ae0cd55302f8274c1b00e353e8d217a0c6f42ac6de45be'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf112d723a00d22ccebe6510a4d314531c43e2a5709bf65fc71c6b8352446254c7aef9b30e9a515e00d7f'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a5804d8bb7603782c4a2b5f5d8a5e7d5253829df468799df5a9e367eec2d2ca3bd3f929534a7b1d91ee7e6'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb867282a0d5959afb95f421ca6b6be816506f41309262ff825b1d2c51e2966e91ba520a565d4dd00e8a0c'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f266d428d6f62d20847874912a86ef9c7c6f27d4725d20fad88601c2a77cc6cfed63f3dc1a42b06b6445'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '458bf5a14cf52cd965cb7465f17e160d4e91dc047f66f4ec0e2ab8909c71a93750fa28c7a8890b9bd0976b0694fa78f6e0ea364ae7e55e7f9c25455c0cde5cc5'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '54ea05b36b8d33633dc03c84da6f54231309b25f5bea8437594dbc6f73383dfd5e190161f9996bafb397e1dba32309778c2411cd92202bf9c528796f714eb7ea'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '34906a3da7a818a4ba94d11f0ce5b08f0b729aab7efdd1042d6c10d1975b32ba900622d4edad44f29378ecf21b10ef84ec32f82252c53816503eaf78a52659e6'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': '16cd216484d0064356b26f2a99804e935e71112e85f5d4db9cb380c8efa8666c2b9f5976ebd23acccf0d285d6cb513bc5bc9f44d00523fdedc875464f054a658'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: de\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': 'c700d3b74c1a565e23291e316788f2a3cbc587fb9a158ac2af5c2371ba5478df1d7931789086f3201e58ed7e22507e9413ef2eda7466389e03b24f8f52d274a8'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: it\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': '446a5058e8da495e8c03346419a3208c7724410653de69949ebed70bc7057b8ff0bc2814fdd9a004b9f22d97d998a198e5ce9f50a649c1ce196a0f30b85dc616'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: fr\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': 'ebe6a26a758bf401eacb942d755fed699dc9c62e357fa603797c926ca9cfa72803588dd58d481571080708a77999c26ce36429cd98d21ce3bf7235aa6ccd0bb2'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_web\n",
      "data: {'tseriesid': 'e91b3fcbda5af81177a4389e2a2e201f50d50af39e85e2be6d64fec705ddae6d4ce61acc6a1b002a4613b090dbd90470974c2e9f8ca60553290459d840f615d7'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: pc_web\n",
      "data: {'tseriesid': 'efeeeb21f3afceb227d72a9f38a232a0c3313e831817094fac473ec255cdc1804ec78392c5fa1d7d27063ce11565e0f5109ae0d1350b5f0f732fd782fb40347b'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: jp\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': 'a3e3188fe9b78e36ae88dfce6cc79c090607623e50febbe1416fc39ceafd261075333173bc2f7fd29f47d44549ab6e64cfbd3ebbf1c4a07419f9dca96505ffb1'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: uk\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '841f9305b2ddb7fb59f5f5b8c56a52c090f96b9f9ea8ea246f6907003db2f7c7469455e62cef5fe676d960cb61ae1c556c1a64abcef8a02bba2a97ec46b24d06'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: us\n",
      "dim_name: platform, dim value: mobile_app\n",
      "data: {'tseriesid': '2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb8b627477c9cadb36aa1d4dd487a2205784373880603dbf223376831496511312d564a755812ad9cdac'}\n",
      "t: time.struct_time(tm_year=2021, tm_mon=7, tm_mday=30, tm_hour=15, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=211, tm_isdst=-1)\n",
      "File name: ./data/ecommerce/live/20210730/1500/20210730_150000.csv\n",
      "dim_name: marketplace, dim value: es\n",
      "dim_name: platform, dim value: mobile_app\n",
      "Anomalies saved in dataframe.\n",
      "\n",
      "df_anomalies_by_ts:\n",
      "              timestamp marketplace    platform  views  revenue  \\\n",
      "0   2021-07-30 15:00:00          de  mobile_app    338   336.84   \n",
      "1   2021-07-30 15:00:00          de      pc_web    386   384.34   \n",
      "2   2021-07-30 15:00:00          es  mobile_app    327   325.80   \n",
      "3   2021-07-30 15:00:00          es  mobile_web    394   392.50   \n",
      "4   2021-07-30 15:00:00          fr  mobile_app    243   242.31   \n",
      "5   2021-07-30 15:00:00          it  mobile_web    263   262.47   \n",
      "6   2021-07-30 15:00:00          it      pc_web    305   303.73   \n",
      "7   2021-07-30 15:00:00          jp  mobile_app    440   438.56   \n",
      "8   2021-07-30 15:00:00          jp  mobile_web    334   333.00   \n",
      "9   2021-07-30 15:00:00          jp      pc_web    340   339.24   \n",
      "10  2021-07-30 15:00:00          uk  mobile_app    334   333.00   \n",
      "11  2021-07-30 15:00:00          uk  mobile_web    361   359.87   \n",
      "12  2021-07-30 15:00:00          uk      pc_web    432   430.89   \n",
      "13  2021-07-30 15:00:00          us  mobile_app    229   228.88   \n",
      "14  2021-07-30 16:00:00          de  mobile_app    371   369.95   \n",
      "15  2021-07-30 16:00:00          de      pc_web    392   391.06   \n",
      "16  2021-07-30 16:00:00          es  mobile_web    410   408.33   \n",
      "17  2021-07-30 16:00:00          it      pc_web    347   346.44   \n",
      "18  2021-07-30 16:00:00          jp  mobile_web    345   344.04   \n",
      "19  2021-07-30 16:00:00          jp      pc_web    365   363.71   \n",
      "20  2021-07-30 16:00:00          uk  mobile_app    370   368.51   \n",
      "21  2021-07-30 16:00:00          uk  mobile_web    358   356.51   \n",
      "22  2021-07-30 16:00:00          uk      pc_web    440   439.04   \n",
      "23  2021-07-30 16:00:00          us  mobile_app    264   263.43   \n",
      "24  2021-07-30 17:00:00          de  mobile_app    394   392.98   \n",
      "25  2021-07-30 17:00:00          de      pc_web    388   387.22   \n",
      "26  2021-07-30 17:00:00          es  mobile_web    408   406.42   \n",
      "27  2021-07-30 17:00:00          it      pc_web    379   378.11   \n",
      "28  2021-07-30 17:00:00          jp  mobile_web    348   346.92   \n",
      "29  2021-07-30 17:00:00          jp      pc_web    382   380.98   \n",
      "30  2021-07-30 17:00:00          uk  mobile_app    391   389.62   \n",
      "31  2021-07-30 17:00:00          uk  mobile_web    340   338.76   \n",
      "32  2021-07-30 17:00:00          uk      pc_web    436   434.25   \n",
      "33  2021-07-30 17:00:00          us  mobile_app    300   298.93   \n",
      "34  2021-07-30 18:00:00          de  mobile_app    407   405.94   \n",
      "35  2021-07-30 18:00:00          de      pc_web    374   372.83   \n",
      "36  2021-07-30 18:00:00          es  mobile_web    404   403.06   \n",
      "37  2021-07-30 18:00:00          it      pc_web    405   403.54   \n",
      "38  2021-07-30 18:00:00          jp  mobile_web    346   344.52   \n",
      "39  2021-07-30 18:00:00          jp      pc_web    389   388.18   \n",
      "40  2021-07-30 18:00:00          uk  mobile_app    408   406.42   \n",
      "41  2021-07-30 18:00:00          uk  mobile_web    314   312.85   \n",
      "42  2021-07-30 18:00:00          uk      pc_web    419   417.45   \n",
      "43  2021-07-30 18:00:00          us  mobile_app    334   333.48   \n",
      "\n",
      "                                            tseriesid  \\\n",
      "0   07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
      "1   67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
      "2   2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb...   \n",
      "3   83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
      "4   446a5058e8da495e8c03346419a3208c7724410653de69...   \n",
      "5   34906a3da7a818a4ba94d11f0ce5b08f0b729aab7efdd1...   \n",
      "6   c700d3b74c1a565e23291e316788f2a3cbc587fb9a158a...   \n",
      "7   efeeeb21f3afceb227d72a9f38a232a0c3313e83181709...   \n",
      "8   ebe6a26a758bf401eacb942d755fed699dc9c62e357fa6...   \n",
      "9   7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a580...   \n",
      "10  a3e3188fe9b78e36ae88dfce6cc79c090607623e50febb...   \n",
      "11  54ea05b36b8d33633dc03c84da6f54231309b25f5bea84...   \n",
      "12  e91b3fcbda5af81177a4389e2a2e201f50d50af39e85e2...   \n",
      "13  dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921a...   \n",
      "14  07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
      "15  67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
      "16  83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
      "17  83e8e8bc0d559d548d2ccea76f087325b26a3defa7c6d0...   \n",
      "18  dfd68a1948784ac73f34bc888bd1f9613b942ddd88e988...   \n",
      "19  7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a580...   \n",
      "20  5ca58fe57ba9367b6fae544425f551d09896b71ad7ec93...   \n",
      "21  54ea05b36b8d33633dc03c84da6f54231309b25f5bea84...   \n",
      "22  458bf5a14cf52cd965cb7465f17e160d4e91dc047f66f4...   \n",
      "23  dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921a...   \n",
      "24  07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
      "25  67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
      "26  83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
      "27  83e8e8bc0d559d548d2ccea76f087325b26a3defa7c6d0...   \n",
      "28  dfd68a1948784ac73f34bc888bd1f9613b942ddd88e988...   \n",
      "29  7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a580...   \n",
      "30  5ca58fe57ba9367b6fae544425f551d09896b71ad7ec93...   \n",
      "31  54ea05b36b8d33633dc03c84da6f54231309b25f5bea84...   \n",
      "32  458bf5a14cf52cd965cb7465f17e160d4e91dc047f66f4...   \n",
      "33  dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921a...   \n",
      "34  07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
      "35  67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
      "36  83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
      "37  83e8e8bc0d559d548d2ccea76f087325b26a3defa7c6d0...   \n",
      "38  dfd68a1948784ac73f34bc888bd1f9613b942ddd88e988...   \n",
      "39  7d0bf2f3e9977fe0ad3f8c8bdf554d8331d1f86740a580...   \n",
      "40  5ca58fe57ba9367b6fae544425f551d09896b71ad7ec93...   \n",
      "41  54ea05b36b8d33633dc03c84da6f54231309b25f5bea84...   \n",
      "42  458bf5a14cf52cd965cb7465f17e160d4e91dc047f66f4...   \n",
      "43  dcf3cf20e07f4351a24c6f88ca6317f0b28e7b59d0921a...   \n",
      "\n",
      "                        anomaly_group_id anomaly_metric  anomaly_metric_value  \n",
      "0   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                338.00  \n",
      "1   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                386.00  \n",
      "2   2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                327.00  \n",
      "3   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                394.00  \n",
      "4   2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                243.00  \n",
      "5   2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                263.00  \n",
      "6   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                305.00  \n",
      "7   2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                440.00  \n",
      "8   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                334.00  \n",
      "9   70fda132-89c3-48c8-8285-6a2b5e6ad468          views                340.00  \n",
      "10  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                334.00  \n",
      "11  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                361.00  \n",
      "12  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                432.00  \n",
      "13  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                229.00  \n",
      "14  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                369.95  \n",
      "15  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                391.06  \n",
      "16  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                408.33  \n",
      "17  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                346.44  \n",
      "18  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                344.04  \n",
      "19  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                363.71  \n",
      "20  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                368.51  \n",
      "21  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                356.51  \n",
      "22  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                439.04  \n",
      "23  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                263.43  \n",
      "24  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                392.98  \n",
      "25  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                387.22  \n",
      "26  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                406.42  \n",
      "27  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                378.11  \n",
      "28  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                346.92  \n",
      "29  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                380.98  \n",
      "30  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                389.62  \n",
      "31  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                338.76  \n",
      "32  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                434.25  \n",
      "33  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                298.93  \n",
      "34  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                405.94  \n",
      "35  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                372.83  \n",
      "36  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                403.06  \n",
      "37  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                403.54  \n",
      "38  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                344.52  \n",
      "39  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                388.18  \n",
      "40  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                406.42  \n",
      "41  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                312.85  \n",
      "42  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                417.45  \n",
      "43  70fda132-89c3-48c8-8285-6a2b5e6ad468        revenue                333.48  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def datetime_from_string(s):\n",
    "    try:\n",
    "        dt = datetime.datetime.fromisoformat(s.split(\"[\")[0])\n",
    "    except ValueError:\n",
    "        dt = datetime.datetime.strptime(s.split(\"[\")[0], \"%Y-%m-%dT%H:%MZ\")\n",
    "    \n",
    "    return dt\n",
    "\n",
    "def get_input_file_name(dt):\n",
    "    time_tuple = t.timetuple()\n",
    "    print(\"t: {}\".format(time_tuple))\n",
    "    year = str(time_tuple.tm_year).zfill(4)\n",
    "    mon = str(time_tuple.tm_mon).zfill(2)\n",
    "    day = str(time_tuple.tm_mday).zfill(2)\n",
    "    hour = str(time_tuple.tm_hour).zfill(2)\n",
    "    minute = str(time_tuple.tm_min).zfill(2)\n",
    "    sec = str(time_tuple.tm_sec).zfill(2)\n",
    "    file_name = '{6}/{7}/live/{0}{1}{2}/{3}{4}/{0}{1}{2}_{3}{4}{5}.csv'.format(year, mon, day, hour, minute, sec, DIR_PATH, DATASET_NAME)\n",
    "        \n",
    "    return file_name\n",
    "    \n",
    "    \n",
    "# Since our metrics period is 1 hour\n",
    "frequency_timedelta = datetime.timedelta(hours=1)\n",
    "\n",
    "df_anomalies_list = []\n",
    "dimension_names_set = set()\n",
    "\n",
    "time_series_list = []\n",
    "df_anomaly_file = pd.DataFrame()\n",
    "\n",
    "for anomaly_group in anomaly_groups:\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    pprint.pprint(anomaly_group, width = 2)\n",
    "    \n",
    "    start_time = datetime_from_string( anomaly_group[\"StartTime\"] )\n",
    "    end_time = datetime_from_string( anomaly_group[\"EndTime\"] )\n",
    "    \n",
    "    anomaly_group_id = anomaly_group[\"AnomalyGroupId\"]\n",
    "    anomaly_group_score = anomaly_group[\"AnomalyGroupScore\"]\n",
    "    primary_metric_name = anomaly_group[\"PrimaryMetricName\"]\n",
    "    \n",
    "    next_token = None\n",
    "\n",
    "    while True:    \n",
    "\n",
    "        params = {\n",
    "            \"AnomalyDetectorArn\" : ecom_anomaly_detector_arn,\n",
    "            \"AnomalyGroupId\" : anomaly_group_id,\n",
    "            \"MetricName\" : primary_metric_name,\n",
    "            \"MaxResults\" : 100,\n",
    "        }\n",
    "\n",
    "        if next_token:\n",
    "            params[\"NextToken\"] = next_token\n",
    "\n",
    "        anomaly_group_time_series_response = L4M.list_anomaly_group_time_series( **params )\n",
    "\n",
    "        time_series_list += anomaly_group_time_series_response[\"TimeSeriesList\"]\n",
    "        \n",
    "        if \"NextToken\" in response:\n",
    "            next_token = response[\"NextToken\"]\n",
    "            continue\n",
    "\n",
    "        break\n",
    "    \n",
    "    #print(\"\\nAnomaly group time series: \")\n",
    "    #pprint.pprint(anomaly_group_time_series_response, width = 2)\n",
    "\n",
    "    #print(\"\\nTime Series list: {}\".format(time_series_list))\n",
    "\n",
    "    for time_series in time_series_list:\n",
    "        # time_series will have a lists of dimensions, metric values along with associted time series id\n",
    "        data = {}\n",
    "        dimension_dict = {}\n",
    "        dim_names_set = set()\n",
    "        \n",
    "        data['tseriesid'] = time_series['TimeSeriesId']\n",
    "        \n",
    "        for dim_in_tseries in time_series[\"DimensionList\"]:\n",
    "            #dim_names_set.add(dim_in_tseries[\"DimensionName\"])\n",
    "            dimension_dict[dim_in_tseries[\"DimensionName\"]] = dim_in_tseries[\"DimensionValue\"]\n",
    "            #dimension_dict['metric_name'] = primary_metric_name          \n",
    "            \n",
    "            #data[dimension[\"DimensionName\"]] = [ dimension[\"DimensionValue\"]]\n",
    "            dimension_names_set.add(dim_in_tseries[\"DimensionName\"])\n",
    "            #data[primary_metric_name + \"_group_score\"] = [anomaly_group_score]\n",
    "        \n",
    "        print(\"data: {}\".format(data))\n",
    "        \n",
    "        t = start_time\n",
    "        \n",
    "        while t <= end_time:\n",
    "            \n",
    "            file_name = get_input_file_name(t)\n",
    "            print(\"File name: {}\".format(file_name))\n",
    "            \n",
    "            df_from_csv = pd.read_csv(file_name) \n",
    "            #print(\"df_from_csv: {}\".format(df_from_csv))\n",
    "            \n",
    "            df_temp = df_from_csv\n",
    "            # drop rows where the dimension does not match\n",
    "            for dim_name in dimension_dict:\n",
    "                dim_value = dimension_dict[dim_name]\n",
    "                print(\"dim_name: \" + dim_name + \", dim value: \" + dim_value)\n",
    "                df_temp = df_temp[df_temp[dim_name] == dim_value] #drop rows\n",
    "                \n",
    "            df_temp['tseriesid'] = time_series['TimeSeriesId']\n",
    "            df_temp['anomaly_group_id'] = anomaly_group_id\n",
    "            df_temp['anomaly_metric'] = primary_metric_name\n",
    "            df_temp['anomaly_metric_value'] = df_temp[primary_metric_name]\n",
    "            \n",
    "            #print(\"df_temp: {}\".format(df_temp.to_string()))\n",
    "            \n",
    "            df_anomalies_list.append(df_temp)\n",
    "            t += frequency_timedelta\n",
    "\n",
    "\n",
    "if len(df_anomalies_list) > 0:\n",
    "    df_anomalies_by_ts = pd.concat(df_anomalies_list)\n",
    "\n",
    "    # fold multiple metrics into same rows\n",
    "    df_anomalies_by_ts = df_anomalies_by_ts.groupby([\"timestamp\", *dimension_names_set], as_index=False).max() \n",
    "    print(\"Anomalies saved in dataframe.\")\n",
    "else:\n",
    "    print(\"No anomalies found.\")\n",
    "\n",
    "print(\"\\ndf_anomalies_by_ts:\\n\" + str(df_anomalies_by_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>platform</th>\n",
       "      <th>views</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tseriesid</th>\n",
       "      <th>anomaly_group_id</th>\n",
       "      <th>anomaly_metric</th>\n",
       "      <th>anomaly_metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>de</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>338</td>\n",
       "      <td>336.84</td>\n",
       "      <td>07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>de</td>\n",
       "      <td>pc_web</td>\n",
       "      <td>386</td>\n",
       "      <td>384.34</td>\n",
       "      <td>67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>327</td>\n",
       "      <td>325.80</td>\n",
       "      <td>2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb...</td>\n",
       "      <td>2ceec6c2-2f2e-4081-84e2-5884c581e66c</td>\n",
       "      <td>views</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>394</td>\n",
       "      <td>392.50</td>\n",
       "      <td>83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>fr</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>243</td>\n",
       "      <td>242.31</td>\n",
       "      <td>446a5058e8da495e8c03346419a3208c7724410653de69...</td>\n",
       "      <td>2ceec6c2-2f2e-4081-84e2-5884c581e66c</td>\n",
       "      <td>views</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp marketplace    platform  views  revenue  \\\n",
       "0  2021-07-30 15:00:00          de  mobile_app    338   336.84   \n",
       "1  2021-07-30 15:00:00          de      pc_web    386   384.34   \n",
       "2  2021-07-30 15:00:00          es  mobile_app    327   325.80   \n",
       "3  2021-07-30 15:00:00          es  mobile_web    394   392.50   \n",
       "4  2021-07-30 15:00:00          fr  mobile_app    243   242.31   \n",
       "\n",
       "                                           tseriesid  \\\n",
       "0  07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
       "1  67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
       "2  2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb...   \n",
       "3  83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
       "4  446a5058e8da495e8c03346419a3208c7724410653de69...   \n",
       "\n",
       "                       anomaly_group_id anomaly_metric  anomaly_metric_value  \n",
       "0  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 338.0  \n",
       "1  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 386.0  \n",
       "2  2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                 327.0  \n",
       "3  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 394.0  \n",
       "4  2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                 243.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_anomalies_by_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.2. Export the Results\n",
    "\n",
    "Create a CSV file with anomaly results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecommerce-continuous-detector-demo-0730_anomalies.csv\n"
     ]
    }
   ],
   "source": [
    "filename = ecom_anomaly_detector_arn.split(':')[-1] + \"_anomalies.csv\"\n",
    "df_anomalies_by_ts.to_csv(filename, index=False )\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.0. Create a private Workteam in SageMaker Console\n",
    "\n",
    "We do it through the AWS Console because it automatically integrates the workteam with Cognito for secure authentiation. \n",
    "\n",
    "Copy the the ARN of the workteam created through the console and enter it as response to the input command in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "workteam_ARN = 'arn:aws:sagemaker:us-west-2:095351214964:workteam/private-crowd/l4m-reviewers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "while workteam_ARN == '':\n",
    "    workteam_ARN = input(\"Please enter the ARN of the Work Team:\\n\")\n",
    "    if len(workteam_ARN) > 0:\n",
    "        break\n",
    "\n",
    "# WORKTEAM_ARN = arn:aws:sagemaker:us-west-2:095351214964:workteam/private-crowd/l4m-reviewers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "l4m_flowDefinitionName = 'l4m-ecommerce-workflow'\n",
    "\n",
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "l4m_taskUIName = 'l4m-ecommerce-ui'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1. Create a human task UI \n",
    "\n",
    "Create a custom task template using HTML that will be presented to the workers. It uses Crowd HTML web components, a web standard that abstracts HTML markup, CSS, and JavaScript functionality into an HTML tag or set of tags. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human task UI ARN: arn:aws:sagemaker:us-west-2:095351214964:human-task-ui/l4m-ecommerce-ui\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We customized the tabular template for our notebook as below\n",
    "ecom_a2i_template = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "\n",
    "    <div>\n",
    "        <h1>Ecommerce Revenue and Views by Platform and Market</h1>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"margin-left: 40px\">\n",
    "        <h2>Instructions</h2>\n",
    "        <p>The following entries were identified as anomalies.<br/> \n",
    "            Please review the views and revenue scores for the platform and market place.<br/>\n",
    "            Check the radio button to confirm whether it was an anomaly.<br/>\n",
    "            Please enter any optional comments for the anomaly.\n",
    "        </p>\n",
    "        <br>\n",
    "    </div>\n",
    "    <div>\n",
    "    <table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Timestamp</th>\n",
    "        <th>Platform</th>\n",
    "        <th>Market Place</th>\n",
    "        <th>Anomaly metric</th>\n",
    "        <th>metric value</th>\n",
    "        <th>Anomaly?</th>\n",
    "        <th>Comment</th>\n",
    "    </tr>\n",
    "    \n",
    "    {% for entry in task.input.l4m_ecom_anomaly %}\n",
    "\n",
    "        <tr>\n",
    "            <td><crowd-text-area name=\"sno-{{ forloop.index }}\" value=\"{{ forloop.index }}\"></crowd-text-area></td>\n",
    "            <td><crowd-text-area name=\"timestamp-{{ forloop.index }}\" value=\"{{ entry.timestamp }}\"></crowd-text-area></td>\n",
    "            <td><crowd-text-area name=\"platform-{{ forloop.index }}\" value=\"{{ entry.platform }}\"></crowd-text-area></td>\n",
    "            <td><crowd-text-area name=\"marketplace-{{ forloop.index }}\" value=\"{{ entry.marketplace }}\"></crowd-text-area></td>     \n",
    "            <td><crowd-text-area name=\"metric_name-{{ forloop.index }}\" value=\"{{ entry.metric_name }}\"></crowd-text-area></td>     \n",
    "            <td><crowd-text-area name=\"metric_value-{{ forloop.index }}\" value=\"{{ entry.metric_value }}\"></crowd-text-area></td>     \n",
    "            <td><crowd-checkbox name=\"anomaly_found-{{ forloop.index }}\">Anomaly Found</crowd-checkbox></td>\n",
    "            <td>\n",
    "                <div><crowd-input name=\"comment-{{ forloop.index }}\" placeholder=\"Enter optional comment\"></crowd-input>\n",
    "            </td>\n",
    "        </tr>\n",
    "      {% endfor %}\n",
    "    </table>\n",
    "    <br>\n",
    "    </div>\n",
    "</crowd-form>\n",
    "\n",
    "<style>\n",
    "  greenbg {\n",
    "    background: #feee23;\n",
    "    display: block;\n",
    "  }\n",
    "\n",
    "  table {\n",
    "    border-spacing: 0; \n",
    "  }\n",
    "\n",
    "  th {\n",
    "    background-color: #8888ee;\n",
    "    color: #f3f3f3;\n",
    "    font-weight: 700;\n",
    "  }\n",
    "\n",
    "  th, td {\n",
    "      border: 1px solid blue;\n",
    "  }\n",
    "\n",
    "  td {\n",
    "    padding-left: 10px ;\n",
    "    padding-right: 10px ;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "window.chartColors = {\n",
    "  red: 'rgb(255, 99, 132)',\n",
    "  orange: 'rgb(255, 159, 64)',\n",
    "  yellow: 'rgb(255, 205, 86)',\n",
    "  green: 'rgb(75, 192, 192)',\n",
    "  blue: 'rgb(54, 162, 235)',\n",
    "  purple: 'rgb(153, 102, 255)',\n",
    "  grey: 'rgb(231,233,237)'\n",
    "};\n",
    "\n",
    "var signal = \"{{task.input.l4m_ecom_anomaly | to_json}}\";\n",
    "var timestamp = [];\n",
    "var platform = [];\n",
    "var marketplace = [];\n",
    "var metric_name = [];\n",
    "var metric_value = [];\n",
    "\n",
    "  \n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Check if lookout for metrics UI for this example already exists\n",
    "try:\n",
    "    describe_human_task_ui_response = sagemaker_client.describe_human_task_ui(\n",
    "        HumanTaskUiName=l4m_taskUIName\n",
    "    )\n",
    "    #print(\"\\nDescribe human task UI: \")\n",
    "    #pprint.pprint(describe_human_task_ui_response, width = 2)\n",
    "    \n",
    "except:\n",
    "    print(\"Human task UI {} not found\")\n",
    "    describe_human_task_ui_response = {}\n",
    "\n",
    "if not describe_human_task_ui_response:\n",
    "    # Create the human task UI\n",
    "    create_human_task_ui_response = sagemaker_client.create_human_task_ui(\n",
    "        HumanTaskUiName=l4m_taskUIName,\n",
    "        UiTemplate={'Content': ecom_a2i_template}) \n",
    "\n",
    "    print(\"\\nCreate human task ui response: \")\n",
    "    pprint.pprint(create_human_task_ui_response, width = 2)\n",
    "\n",
    "    l4m_review_ui_arn = create_human_task_ui_response['HumanTaskUiArn']\n",
    "else:\n",
    "    l4m_review_ui_arn = describe_human_task_ui_response['HumanTaskUiArn']    \n",
    "    \n",
    "print(\"\\nHuman task UI ARN: {}\".format(l4m_review_ui_arn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2. Create a Human task Workflow \n",
    "\n",
    "We use Amazon Augmented AI's user interface to create a custom task workflow. The new flow is created only if one does not exist already with the same name. The results of human review are stored in an Amazon S3 bucket, which can be accessed by the client application. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 output path: s3://095351214964-us-west-2-lookoutmetrics-lab/ecommerce/a2i-results\n",
      "Flow definition Arn: arn:aws:sagemaker:us-west-2:095351214964:flow-definition/l4m-ecommerce-workflow\n"
     ]
    }
   ],
   "source": [
    "sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "s3_output_path = f's3://' + bucket_name + '/ecommerce' + '/a2i-results'\n",
    "print(\"S3 output path: {}\".format(s3_output_path))\n",
    "\n",
    "# Check if Amazon Lookout For Metrics Workflow exists\n",
    "try:\n",
    "    describe_flow_definition_response = sagemaker_client.describe_flow_definition(\n",
    "        FlowDefinitionName=l4m_flowDefinitionName\n",
    "    )\n",
    "    ###### print describe_flow_definition_response\n",
    "    #print(\"\\nDescribe flow definition response: \")\n",
    "    #pprint.pprint(describe_flow_definition_response, width=2)\n",
    "    \n",
    "except:\n",
    "    describe_flow_definition_response = {}\n",
    "    \n",
    "# Create Amazon Lookout For Metrics Workflow if it does not exist already\n",
    "\n",
    "if not describe_flow_definition_response:\n",
    "    create_workflow_definition_response = sagemaker_client.create_flow_definition(\n",
    "        FlowDefinitionName = l4m_flowDefinitionName,\n",
    "        RoleArn=sagemaker_role_arn,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": workteam_ARN,\n",
    "            \"HumanTaskUiArn\": l4m_review_ui_arn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Review the anomalies detected by Amazon Lookout for Metrics\",\n",
    "            \"TaskTitle\": \"Ecommerce Anomalies Review\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : s3_output_path\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Wait until the newly created flow becomes Active\n",
    "    while True:\n",
    "\n",
    "        response = sagemaker_client.describe_flow_definition(FlowDefinitionName=l4m_flowDefinitionName)\n",
    "        print(response['FlowDefinitionStatus'])\n",
    "        if (response['FlowDefinitionStatus'] == 'Active'):\n",
    "            print(\"Flow Definition is active\")\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] \n",
    "\n",
    "else:\n",
    "    flowDefinitionArn = describe_flow_definition_response['FlowDefinitionArn'] \n",
    "        \n",
    "\n",
    "print(\"Flow definition Arn: {}\".format(flowDefinitionArn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>platform</th>\n",
       "      <th>views</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tseriesid</th>\n",
       "      <th>anomaly_group_id</th>\n",
       "      <th>anomaly_metric</th>\n",
       "      <th>anomaly_metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>de</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>338</td>\n",
       "      <td>336.84</td>\n",
       "      <td>07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>de</td>\n",
       "      <td>pc_web</td>\n",
       "      <td>386</td>\n",
       "      <td>384.34</td>\n",
       "      <td>67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>327</td>\n",
       "      <td>325.80</td>\n",
       "      <td>2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb...</td>\n",
       "      <td>2ceec6c2-2f2e-4081-84e2-5884c581e66c</td>\n",
       "      <td>views</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>394</td>\n",
       "      <td>392.50</td>\n",
       "      <td>83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...</td>\n",
       "      <td>70fda132-89c3-48c8-8285-6a2b5e6ad468</td>\n",
       "      <td>views</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-30 15:00:00</td>\n",
       "      <td>fr</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>243</td>\n",
       "      <td>242.31</td>\n",
       "      <td>446a5058e8da495e8c03346419a3208c7724410653de69...</td>\n",
       "      <td>2ceec6c2-2f2e-4081-84e2-5884c581e66c</td>\n",
       "      <td>views</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp marketplace    platform  views  revenue  \\\n",
       "0  2021-07-30 15:00:00          de  mobile_app    338   336.84   \n",
       "1  2021-07-30 15:00:00          de      pc_web    386   384.34   \n",
       "2  2021-07-30 15:00:00          es  mobile_app    327   325.80   \n",
       "3  2021-07-30 15:00:00          es  mobile_web    394   392.50   \n",
       "4  2021-07-30 15:00:00          fr  mobile_app    243   242.31   \n",
       "\n",
       "                                           tseriesid  \\\n",
       "0  07023e36a1a026f1f30a77b1f45f83d0e04cbc899627f2...   \n",
       "1  67cc94bcf3bee4716e9abb7555c1cf6a5909b311c4bbf1...   \n",
       "2  2c6492e0b42887f771cfb49f398c78c22d24b2cfb78bcb...   \n",
       "3  83fcccf0636c7ee0a6f20d4f96f9fe6b42af3e09c8eb86...   \n",
       "4  446a5058e8da495e8c03346419a3208c7724410653de69...   \n",
       "\n",
       "                       anomaly_group_id anomaly_metric  anomaly_metric_value  \n",
       "0  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 338.0  \n",
       "1  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 386.0  \n",
       "2  2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                 327.0  \n",
       "3  70fda132-89c3-48c8-8285-6a2b5e6ad468          views                 394.0  \n",
       "4  2ceec6c2-2f2e-4081-84e2-5884c581e66c          views                 243.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !aws s3 sync {data_dirname}/ecommerce/ s3://{bucket_name}/ecommerce/ --quiet\n",
    "\n",
    "#!aws s3 cp ecommerce-continuous-detector_anomalies.csv s3://{bucket_name}/ecommerce/\n",
    "\n",
    "# Anomaly records were saved in the dataframe in a previous cell. Otherwise read from csv file saved earlier.\n",
    "if len(df_anomalies_by_ts) == 0:\n",
    "    df_anomalies_by_ts = pd.read_csv(\"./ecommerce-continuous-detector-demo-1_anomalies\")\n",
    "\n",
    "df_anomalies_by_ts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Create a Python list of anomalies to pass into the human review task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '338.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '386.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'es',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '327.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'es',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '394.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'fr',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '243.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'it',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '263.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'it',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '305.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '440.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '334.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '340.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '334.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '361.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '432.0'},\n",
       " {'timestamp': '2021-07-30 15:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'us',\n",
       "  'metric_name': 'views',\n",
       "  'metric_value': '229.0'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '369.95'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '391.06'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'es',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '408.33'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'it',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '346.44'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '344.04'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '363.71'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '368.51'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '356.51'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '439.04'},\n",
       " {'timestamp': '2021-07-30 16:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'us',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '263.43'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '392.98'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '387.22'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'es',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '406.42'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'it',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '378.11'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '346.92'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '380.98'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '389.62'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '338.76'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '434.25'},\n",
       " {'timestamp': '2021-07-30 17:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'us',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '298.93'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '405.94'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'de',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '372.83'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'es',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '403.06'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'it',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '403.54'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '344.52'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'jp',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '388.18'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '406.42'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '312.85'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'pc_web',\n",
       "  'marketplace': 'uk',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '417.45'},\n",
       " {'timestamp': '2021-07-30 18:00:00',\n",
       "  'platform': 'mobile_app',\n",
       "  'marketplace': 'us',\n",
       "  'metric_name': 'revenue',\n",
       "  'metric_value': '333.48'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tseriesid_list = ecom_anomalies_df['tseriesid'].astype(str).to_list()\n",
    "timestamp_list = df_anomalies_by_ts['timestamp'].astype(str).to_list()\n",
    "platform_list = df_anomalies_by_ts['platform'].astype(str).to_list()\n",
    "marketplace_list = df_anomalies_by_ts['marketplace'].astype(str).to_list()\n",
    "\n",
    "anomaly_metric_list = df_anomalies_by_ts['anomaly_metric'].astype(str).to_list()\n",
    "metric_value_list = df_anomalies_by_ts['anomaly_metric_value'].astype(str).to_list()\n",
    "\n",
    "for i in range(len(timestamp_list)):\n",
    "     ecom_review_list = [ {'timestamp': timestamp_list[i], \\\n",
    "                            'platform': platform_list[i], \\\n",
    "                            'marketplace': marketplace_list[i], \\\n",
    "                            'metric_name': anomaly_metric_list[i], \\\n",
    "                            'metric_value': metric_value_list[i]} \\\n",
    "                            for i in range(len(timestamp_list))\n",
    "\n",
    "                        ]\n",
    "        \n",
    "ip_content = {\"l4m_ecom_anomaly\": ecom_review_list} # passed into workflow\n",
    "\n",
    "ecom_review_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3. Start the human review loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i_client = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "humanLoopName = str(uuid.uuid4())\n",
    "\n",
    "start_human_loop_response = a2i_client.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(ip_content)\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(\"\\nStart human loop response: \")\n",
    "#pprint.pprint(start_human_loop_response, width=2)\n",
    "\n",
    "print(\"\\nHuman Loop ARN: {}\".format(start_human_loop_response['HumanLoopArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "By this time we should have already created a Workteam in the cosole and provided its ARN as input to an ealier cell. We use the Workteam name from the Workteam ARN, to find the URL of the portal for providing feedback on anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workteamName = workteam_ARN[workteam_ARN.rfind('/') + 1:]\n",
    "\n",
    "describe_workteam_response = sagemaker_client.describe_workteam(WorkteamName=workteamName)\n",
    "\n",
    "if not describe_workteam_response:\n",
    "    print(\"You need to log into SageMaker console and create a Workteam\")\n",
    "    sys.exit()\n",
    " \n",
    "#print(\"\\nDescribe work team response: \")\n",
    "#pprint.pprint(describe_workteam_response, width=2)\n",
    "\n",
    "workteam_portal = 'https://' + describe_workteam_response['Workteam']['SubDomain']\n",
    "\n",
    "\n",
    "print(\"\\nLog into the work team portal link provided below, and review the anomalies.\\n\")\n",
    "\n",
    "print (\"=\" * 60)\n",
    "print(\"Portal URL\\n{}\".format(workteam_portal))\n",
    "print ('=' * 60)\n",
    "\n",
    "#print('https://' + sagemaker_client.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4. Complete the review\n",
    "\n",
    "The URL to the portal was printed out in the last step. Open the URL in a browser and log in with credentials of the human review worker. </br>\n",
    "You should have sent an invitation email to a worker for joining the workteam when creating the work team in the Amazon A2I console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_complete = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while review_complete == 'N':\n",
    "    \n",
    "    review_complete = input(\"\\nPlease log into A2I Portal and complete the review.\\nIs the review complete (Y/N)?\")\n",
    "    \n",
    "    if review_complete == 'Y':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops_s3_output = \"\"\n",
    "\n",
    "try:\n",
    "    describe_human_loop_response = a2i_client.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "    print(\"\\nDescribe human loop response: \")\n",
    "    pprint.pprint(describe_human_loop_response, width=2)\n",
    "    \n",
    "    completed_human_loops_s3_output = describe_human_loop_response[\"HumanLoopOutput\"][\"OutputS3Uri\"]\n",
    "    print(\"HumanLoop Status: {}\".format(describe_human_loop_response[\"HumanLoopStatus\"]))\n",
    "except:\n",
    "    print(\"Error getting human loop\")\n",
    "\n",
    "\n",
    "#print(\"\\nHumanLoop Name: {}\".format(humanLoopName))\n",
    "#print(\"HumanLoop Status: {}\".format(describe_human_loop_response[\"HumanLoopStatus\"]))\n",
    "print(\"\\nOutput in S3 at: \\n{}\".format(describe_human_loop_response[\"HumanLoopOutput\"][\"OutputS3Uri\"]))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "json_output = ''\n",
    "\n",
    "s3_bucket_name, s3_object_name = completed_human_loops_s3_output.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "print(\"S3 bucket name: {}\".format(s3_bucket_name))\n",
    "print(\"S3 object name: {}\".format(s3_object_name))\n",
    "\n",
    "# Amazon S3 client \n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "try:\n",
    "    get_object_response = s3_client.get_object(Bucket=s3_bucket_name, Key=s3_object_name)\n",
    "    content = get_object_response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')\n",
    "\n",
    "except:\n",
    "    print(\"Error getting S3 object: {}\".format(completed_human_loops_s3_output))\n",
    "\n",
    "#print(\"\\nS3 get object response: \")\n",
    "#pprint.pprint(get_object_response, width=2)\n",
    "\n",
    "\n",
    "review_result = json_output['humanAnswers'][0]['answerContent']\n",
    "\n",
    "#print(review_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7.0. Update human review feedback in Amazon Lookout For Metrics\n",
    "\n",
    "This will help to improve the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not L4M:\n",
    "    L4M = boto3.client( \"lookoutmetrics\")\n",
    "\n",
    "col_name_suffix = 1\n",
    "anomaly_col_name = 'anomaly_found-' + str(col_name_suffix)\n",
    "\n",
    "while anomaly_col_name in review_result:\n",
    "    \n",
    "    #tseriesid = review_result['tseriesid-' + str(col_name_suffix)]    \n",
    "    \n",
    "    print(\"\\n{}\".format(str(col_name_suffix)))\n",
    "    \n",
    "    is_anomaly = review_result[anomaly_col_name]['on']\n",
    "    print(\"Is Anomaly: {}\".format(is_anomaly))\n",
    "        \n",
    "    #print(df_anomalies_by_ts.loc[(df_anomalies_by_ts['timestamp'] == timestamp) & (df_anomalies_by_ts['marketplace'] ==marketplace) & (df_anomalies_by_ts['platform'] ==platform)])\n",
    "    \n",
    "    # get corresponding time series id and anomaly group id from dataframe df_anomalies_by_ts\n",
    "    row_value = df_anomalies_by_ts.loc[(df_anomalies_by_ts['timestamp'] == timestamp) & (df_anomalies_by_ts['marketplace'] ==marketplace) & (df_anomalies_by_ts['platform'] ==platform)]\n",
    "    #print(\"Row :{}\".format(row_value))\n",
    "\n",
    "    tseriesid = row_value['tseriesid'].tolist()[0]\n",
    "    print(\"tseriesid: {}\".format(tseriesid))\n",
    "    \n",
    "    anomaly_group_id = row_value['anomaly_group_id'].tolist()[0]\n",
    "    print(\"Anomaly group id: {}\".format(anomaly_group_id))\n",
    "   \n",
    "    #print('\\nPut Feedback Response: {}'.format(put_feedback_response))\n",
    "    \n",
    "    col_name_suffix += 1\n",
    "    anomaly_col_name = 'anomaly_found-' + str(col_name_suffix)\n",
    "\n",
    "    put_feedback_response = L4M.put_feedback(\n",
    "            AnomalyDetectorArn=ecom_anomaly_detector_arn,\n",
    "            AnomalyGroupTimeSeriesFeedback={\n",
    "                'AnomalyGroupId': anomaly_group_id,\n",
    "                'TimeSeriesId': tseriesid,\n",
    "                'IsAnomaly': is_anomaly}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 8.0. Clean up resources \n",
    "\n",
    "You can start to cleanup the resources that were created. This will erase all the resources that have been created, so wait to run this until you are sure you wish to delete everything.\n",
    "\n",
    "\n",
    "**Note that since we created a continuous detector, it will continue to run once every hour until it is deleted.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the detector exists\n",
    "answer = input(\"Delete resources? (y/n)\")\n",
    "\n",
    "if answer in [\"y\", \"Y\", \"yes\", \"YES\"]:\n",
    "    delete_resources = True\n",
    "else:\n",
    "    delete_resources = False\n",
    "    \n",
    "if delete_resources:\n",
    "    L4M.delete_anomaly_detector( AnomalyDetectorArn = ecom_anomaly_detector_arn )\n",
    "    while True:\n",
    "        try:\n",
    "            response = lookoutmetrics_client.describe_anomaly_detector( AnomalyDetectorArn = arn )\n",
    "            if response[\"Status\"] == \"DELETING\":\n",
    "                print(\"status: DELETING\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            break\n",
    "        except lookoutmetrics_client.exceptions.ResourceNotFoundException:\n",
    "            break\n",
    "\n",
    "    iam = boto3.client(\"iam\")\n",
    "    iam.detach_role_policy( PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\", RoleName = role_name )\n",
    "    iam.detach_role_policy( PolicyArn = \"arn:aws:iam::aws:policy/AmazonSNSFullAccess\", RoleName = role_name )\n",
    "    iam.delete_role(RoleName=role_name)\n",
    "    print(\"Deleted %s\" % role_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the resources\n",
    "\n",
    "if delete_resources:\n",
    "    \n",
    "    # Check the status of human loop\n",
    "    describe_human_loop_response = a2i_client.describe_human_loop(\n",
    "        HumanLoopName=humanLoopName\n",
    "    )\n",
    "\n",
    "    print(\"\\nDescribe human loop response: \")\n",
    "    pprint.pprint(describe_human_loop_response, width=2)\n",
    "\n",
    "\n",
    "    # \n",
    "    if describe_human_loop_response['HumanLoopStatus'] ==  \"InProgress\":\n",
    "        stop_human_loop_response = a2i_client.stop_human_loop(\n",
    "            HumanLoopName=humanLoopName\n",
    "        )\n",
    "\n",
    "        # Wait until human loop has stopped\n",
    "        while True:\n",
    "            describe_human_loop_response = a2i_client.describe_human_loop(\n",
    "                HumanLoopName=humanLoopName\n",
    "            )\n",
    "            if describe_human_loop_response['HumanLoopStatus'] in [\"Stopped\", \"Failed\", \"Completed\"]:\n",
    "                break\n",
    "            time.sleep(5)\n",
    "    \n",
    "    \n",
    "        # Delete human loop\n",
    "        delete_human_loop_response = a2i_client.delete_human_loop(\n",
    "            HumanLoopName=humanLoopName\n",
    "        )\n",
    "        print(\"\\nDelete human loop response: \")\n",
    "        pprint.pprint(delete_human_loop_response, width=2)\n",
    "    \n",
    "    # Delete work flow.\n",
    "    delete_flow_definition_response = sagemaker_client.delete_flow_definition(\n",
    "         FlowDefinitionName=l4m_flowDefinitionName\n",
    "    )\n",
    "\n",
    "    print(\"\\nDelete flow definition response: \")\n",
    "    pprint.pprint(delete_flow_definition_response, width=2)\n",
    "\n",
    "    # Delete human task UI\n",
    "    # Check if Amazon lookout for metrics UI exists\n",
    "    try:\n",
    "        delete_human_task_ui_response = sagemaker_client.delete_human_task_ui(\n",
    "            HumanTaskUiName=l4m_taskUIName\n",
    "        )\n",
    "        print(\"\\nDelete human task UI: \")\n",
    "        pprint.pprint(delete_human_task_ui_response, width = 2)\n",
    "    except:\n",
    "        print(\"Human task UI {} not found\".format(l4m_taskUIName))\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
