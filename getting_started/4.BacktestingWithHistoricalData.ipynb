{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting on Historical Data for Amazon Lookout for Metrics\n",
    "\n",
    "Amazon Lookout for Metrics also supports backtesting against your historical information and in this notebook we will demonstrate this functionality on the same e-commerce data. Once the backtesting job has completed you can see all of the anomalies that Amazon Lookout for Metrics detected in the last 20% of your historical data. From here you can begin to unpack the kinds of results you will see from Amazon Lookout for Metrics in the future when you start streaming in new data. **NOTE YOU MUST CREATE A NEW DETECTOR TO LEVERAGE REAL TIME DATA. BACKTESTING IS ONLY FOR EXPLORATION.**\n",
    "\n",
    "This notebook assumes that you already completed the prerequisites in the `1.PrereqSetupPackages.ipynb`, `2.PrereqSetupData.ipynb`, and `3.GettingStartedWithLiveData.ipynb`. If you have not, go back and complete those first, then give backtesting a whirl while you are waiting for the real time anomalies to alert you!\n",
    "\n",
    "First restore the variables from the previous notebook and then import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the last notebook, connect to AWS through the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M = boto3.client( \"lookoutmetrics\", region_name=\"us-west-2\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Detector\n",
    "\n",
    "This step is identical to the one in the previous notebook. Here, we're simply creating a diffrent `detector` that we will use for backtesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"initial-lookoutmetrics-backtesting-test\"\n",
    "\n",
    "frequency = \"PT1H\" # one of 'P1D', 'PT1H', 'PT10M' and 'PT5M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_anomaly_detector( \n",
    "    AnomalyDetectorName = project + \"-detector\",\n",
    "    AnomalyDetectorDescription = \"My Detector\",\n",
    "    AnomalyDetectorConfig = {\n",
    "        \"AnomalyDetectorFrequency\" : \"PT1H\",\n",
    "    },\n",
    ")\n",
    "\n",
    "anomaly_detector_arn = response[\"AnomalyDetectorArn\"]\n",
    "anomaly_detector_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrics\n",
    "\n",
    "After creating a detector, we need to point it to the s3 path for our backtest data. This process is also, similar to the one from the previous notebook.\n",
    "\n",
    "First, let's create a role that can work with the Amazon Lookout for Metrics service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"L4MTestRole\"\n",
    "role_arn = utility.get_or_create_iam_role(role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a metric set for our detector that point to the backtest data in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_backtest = 's3://'+ s3_bucket + '/ecommerce/backtest/'\n",
    "s3_path_backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"AnomalyDetectorArn\": anomaly_detector_arn,\n",
    "    \"MetricSetName\" : project + '-metric-set-1',\n",
    "    \"MetricList\" : [\n",
    "        {\n",
    "            \"MetricName\" : \"views\",\n",
    "            \"AggregationFunction\" : \"AVG\",\n",
    "        },\n",
    "        {\n",
    "            \"MetricName\" : \"revenue\",\n",
    "            \"AggregationFunction\" : \"SUM\",\n",
    "        },\n",
    "    ],\n",
    "\n",
    "    \"DimensionList\" : [ \"platform\", \"marketplace\" ],\n",
    "\n",
    "    \"TimestampColumn\" : {\n",
    "        \"ColumnName\" : \"timestamp\",\n",
    "        \"ColumnFormat\" : \"yyyy-MM-dd HH:mm:ss\",\n",
    "    },\n",
    "\n",
    "    #\"Delay\" : 120, # seconds the detector will wait before attempting to read latest data per current time and detection frequency below\n",
    "    \"MetricSetFrequency\" : frequency,\n",
    "\n",
    "    \"MetricSource\" : {\n",
    "        \"S3SourceConfig\": {\n",
    "            \"RoleArn\" : role_arn,\n",
    "            \"HistoricalDataPathList\": [\n",
    "                s3_path_backtest,\n",
    "            ],\n",
    "#            \"TemplatedPathList\": [\n",
    "#                s3_path_format,\n",
    "#            ],\n",
    "\n",
    "            \"FileFormatDescriptor\" : {\n",
    "                \"CsvFormatDescriptor\" : {\n",
    "                    \"FileCompression\" : \"NONE\",\n",
    "                    \"Charset\" : \"UTF-8\",\n",
    "                    \"ContainsHeader\" : True,\n",
    "                    \"Delimiter\" : \",\",\n",
    "#                    \"HeaderList\" : [\n",
    "#                        \"platform\",\n",
    "#                        \"marketplace\",\n",
    "#                        \"timestamp\",\n",
    "#                        \"views\",\n",
    "#                        \"revenue\"\n",
    "#                    ],\n",
    "                    \"QuoteSymbol\" : '\"'\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_metric_set( ** params )\n",
    "\n",
    "metric_set_arn = response[\"MetricSetArn\"]\n",
    "metric_set_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the Detector and Execute Backtesting\n",
    "\n",
    "Now that the MetricSet has been specified, we are ready to start backtesting, that's done by activating the back test anomaly detector. The backtesting process can take 25 minutes or so, so feel free to take a break and grab a snack and catch up on any articles you have saved. Note, when it says `BACK_TEST_ACTIVE` the service has trained a model and is now evaluating the holdout period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.back_test_anomaly_detector(AnomalyDetectorArn = anomaly_detector_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.wait_anomaly_detector( L4M, anomaly_detector_arn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "\n",
    "After backtesting is finished, you can visually validate the historical anomalies via the console or inspect the results by running the commands below. It is recommended that you start your exploration in the console however. The console will be your tool for viewing and understanding alerts in the online mode later, this way you start to get familiar with the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_groups = []\n",
    "next_token = None\n",
    "first_response = None\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\" : anomaly_detector_arn,\n",
    "        \"SensitivityThreshold\" : 50,\n",
    "        \"MaxResults\" : 100,\n",
    "    }\n",
    "    \n",
    "    if next_token:\n",
    "        params[\"NextToken\"] = next_token\n",
    "    \n",
    "    response = L4M.list_anomaly_group_summaries( **params )\n",
    "    if first_response is None:\n",
    "        first_response = response\n",
    "    \n",
    "    anomaly_groups += response[\"AnomalyGroupSummaryList\"]\n",
    "    \n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "        continue\n",
    "    break\n",
    "\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to dive even deeper into a specific anomaly group, simlpy choose your anomaly group of interest and drill down to it's time-series. Here we will use the first anomaly group in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_group_id = anomaly_groups[0][\"AnomalyGroupId\"]\n",
    "\n",
    "anomaly_group_time_series = []\n",
    "next_token = None\n",
    "first_response = None\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\" : anomaly_detector_arn,\n",
    "        \"AnomalyGroupId\" : anomaly_group_id,\n",
    "        \"MetricName\" : \"views\",\n",
    "        \"MaxResults\" : 10,\n",
    "    }\n",
    "    \n",
    "    if next_token:\n",
    "        params[\"NextToken\"] = next_token\n",
    "\n",
    "    response = L4M.list_anomaly_group_time_series( **params )\n",
    "    if first_response is None:\n",
    "        first_response = response\n",
    "    \n",
    "    anomaly_group_time_series += response[\"TimeSeriesList\"]\n",
    "    \n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "        continue\n",
    "    break\n",
    "\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_group_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Once we have completed backtesting, we can start to cleanup the resources we created. Before cleaning up, you can visit the \"Anomalies\" page of the Amazon Lookout for Metrics console, and visually check the detected anomalies.\n",
    "\n",
    "Note this will erase all the resources that have been created, so wait to run this until you are sure you wish to delete everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = input(\"Delete resources? (y/n)\")\n",
    "if answer==\"y\":\n",
    "    delete_resources = True\n",
    "else:\n",
    "    delete_resources = False\n",
    "    \n",
    "if delete_resources:\n",
    "    L4M.delete_anomaly_detector( AnomalyDetectorArn = anomaly_detector_arn )\n",
    "    utility.wait_delete_anomaly_detector( L4M, anomaly_detector_arn )\n",
    "    utility.delete_iam_role(role_name)\n",
    "else:\n",
    "    print(\"Not deteleting resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
