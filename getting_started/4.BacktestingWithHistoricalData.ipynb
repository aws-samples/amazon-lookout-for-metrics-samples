{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Backtesting on Historical Data for Amazon Lookout for Metrics\n",
    "\n",
    "Amazon Lookout for Metrics also supports backtesting against your historical information and in this notebook we will demonstrate this functionality on the same e-commerce data. Once the backtesting job has completed you can see all of the anomalies that Amazon Lookout for Metrics detected in the last 20% of your historical data. From here you can begin to unpack the kinds of results you will see from Amazon Lookout for Metrics in the future when you start streaming in new data. **NOTE YOU MUST CREATE A NEW DETECTOR TO LEVERAGE REAL TIME DATA. BACKTESTING IS ONLY FOR EXPLORATION.**\n",
    "\n",
    "This notebook assumes that you already completed the prerequisites in the `1.PrereqSetupPackages.ipynb` and `2.PrereqSetupData.ipynb`. If you have not, go back and complete those first, then give backtesting a whirl while you are waiting for the real time anomalies to alert you!\n",
    "\n",
    "First restore the variables from the previous notebook and then import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the last notebook, connect to AWS through the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-west-2\"\n",
    "session = boto3.Session(region_name = region)\n",
    "\n",
    "# FIXME : Beta endpoint\n",
    "L4M = session.client( \"lookoutmetrics\", endpoint_url='https://lookoutmetrics-beta.us-west-2.amazonaws.com/' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Detector\n",
    "\n",
    "This step is identical to the one in the previous notebook. Here, we're simply creating a diffrent `detector` that we will use for backtesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"initial-lookoutmetrics-backtesting\"\n",
    "\n",
    "frequency = \"PT1H\" # one of 'P1D', 'PT1H', 'PT10M' and 'PT5M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_anomaly_detector( \n",
    "    AnomalyDetectorName = project + \"-detector\",\n",
    "    AnomalyDetectorDescription = \"My Detector\",\n",
    "    AnomalyDetectorConfig = {\n",
    "        \"AnomalyDetectorFrequency\" : \"PT1H\",\n",
    "    },\n",
    ")\n",
    "\n",
    "anomaly_detector_arn = response[\"AnomalyDetectorArn\"]\n",
    "anomaly_detector_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrics\n",
    "\n",
    "After creating a detector, we need to point it to the s3 path for our backtest data. This process is also, similar to the one from the previous notebook.\n",
    "\n",
    "First, let's create a role that can work with the Amazon Lookout for Metrics service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"L4MTestRole\"\n",
    "role_arn = utility.get_or_create_iam_role(role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a metric set for our detector that point to the backtest data in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_backtest = 's3://'+ s3_bucket + '/ecommerce/backtest/'\n",
    "s3_path_backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"AnomalyDetectorArn\": anomaly_detector_arn,\n",
    "    \"MetricSetName\" : project + '-metric-set-1',\n",
    "    \"MetricList\" : [\n",
    "        {\n",
    "            \"MetricName\" : \"views\",\n",
    "            \"AggregationFunction\" : \"AVG\",\n",
    "        },\n",
    "        {\n",
    "            \"MetricName\" : \"revenue\",\n",
    "            \"AggregationFunction\" : \"SUM\",\n",
    "        },\n",
    "    ],\n",
    "\n",
    "    \"DimensionList\" : [ \"platform\", \"marketplace\" ],\n",
    "\n",
    "    \"TimestampColumn\" : {\n",
    "        \"ColumnName\" : \"timestamp\",\n",
    "        \"ColumnFormat\" : \"yyyy-MM-dd HH:mm:ss\",\n",
    "    },\n",
    "\n",
    "    #\"Delay\" : 120, # seconds the detector will wait before attempting to read latest data per current time and detection frequency below\n",
    "    \"MetricSetFrequency\" : frequency,\n",
    "\n",
    "    \"MetricSource\" : {\n",
    "        \"S3SourceConfig\": {\n",
    "            \"RoleArn\" : role_arn,\n",
    "            \"HistoricalDataPathList\": [\n",
    "                s3_path_backtest,\n",
    "            ],\n",
    "#            \"TemplatedPathList\": [\n",
    "#                s3_path_format,\n",
    "#            ],\n",
    "\n",
    "            \"FileFormatDescriptor\" : {\n",
    "                \"CsvFormatDescriptor\" : {\n",
    "                    \"FileCompression\" : \"NONE\",\n",
    "                    \"Charset\" : \"UTF-8\",\n",
    "                    \"ContainsHeader\" : True,\n",
    "                    \"Delimiter\" : \",\",\n",
    "#                    \"HeaderList\" : [\n",
    "#                        \"platform\",\n",
    "#                        \"marketplace\",\n",
    "#                        \"timestamp\",\n",
    "#                        \"views\",\n",
    "#                        \"revenue\"\n",
    "#                    ],\n",
    "                    \"QuoteSymbol\" : '\"'\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_metric_set( ** params )\n",
    "\n",
    "metric_set_arn = response[\"MetricSetArn\"]\n",
    "metric_set_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the Detector and execute backtesting\n",
    "\n",
    "Now that the MetricSet has been specified, we are ready to start backtesting, that's done by activating the back test anomaly detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.back_test_anomaly_detector(AnomalyDetectorArn = anomaly_detector_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.wait_anomaly_detector( L4M, anomaly_detector_arn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "\n",
    "After backtesting is finished, you can visually validate the historical anomalies via the console or inspect the results by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_groups = []\n",
    "next_token = None\n",
    "\n",
    "while True:    \n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\" : anomaly_detector_arn,\n",
    "        \"SensitivityThreshold\" : 50,\n",
    "        \"MaxResults\" : 100,\n",
    "    }\n",
    "    \n",
    "    if next_token:\n",
    "        params[\"NextToken\"] = next_token\n",
    "    \n",
    "    response = L4M.list_anomaly_group_summaries( **params )\n",
    "    stats = response[\"AnomalyGroupStatistics\"]\n",
    "    \n",
    "    anomaly_groups += response[\"AnomalyGroupSummaryList\"]\n",
    "    \n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "        continue\n",
    "    break\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to dive even deeper into a specific anomaly group, simlpy choose your anomaly group of interest and drill down to it's time-series. Here we will use the first anomaly group in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_group_id = anomaly_groups[0][\"AnomalyGroupId\"]\n",
    "\n",
    "response = L4M.list_anomaly_group_time_series(AnomalyDetectorArn = anomaly_detector_arn,\n",
    "                                   AnomalyGroupId=anomaly_group_id,\n",
    "                                   MetricName='views',\n",
    "                                   MaxResults=10,\n",
    "                                  )\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Once we have completed backtesting, we can start to cleanup the resources we created. Before cleaning up, you can visit the \"Anomalies\" page of the Amazon Lookout for Metrics console, and visually check the detected anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = input(\"Delete resources? (y/n)\")\n",
    "if answer==\"y\":\n",
    "    delete_resources = True\n",
    "else:\n",
    "    delete_resources = False\n",
    "    \n",
    "if delete_resources:\n",
    "    #L4M.delete_anomaly_detector( AnomalyDetectorArn = anomaly_detector_arn )\n",
    "    utility.wait_delete_anomaly_detector( L4M, anomaly_detector_arn )\n",
    "else:\n",
    "    print(\"Not deteleting resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
