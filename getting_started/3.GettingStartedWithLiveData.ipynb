{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started With Amazon Lookout for Metrics\n",
    "\n",
    "Amazon Lookout for Metrics can help you identify anomalies within your data regardless of its origin. By following this notebook you will build out a solution using Amazon Lookout for Metrics to capture incoming data and to detect anomalies within it.\n",
    "\n",
    "This guide assumes you completed all the work in `README.md`, if you have not, go back to that first then return\n",
    "\n",
    "## Amazon Lookout for Metrics's Workflow\n",
    "\n",
    "1. Prepare your source data and create an AWS Identity and Access Management (IAM) role that can access the data.\n",
    "2. Create a detector and configure its detection properties.\n",
    "3. Create a metric set:\n",
    "    1. Provide the location of your source data and the IAM permissions needed to access it. \n",
    "    1. Define the metrics that you want to investigate.\n",
    "    1. Attach the dataset to your detector.\n",
    "4. Activate the detector.\n",
    "5. (Optional) Set up alerts to get notified when L4M detects important outliers.\n",
    "6. Inspect the detected outliers to figure out their root causes.\n",
    "7. Provide feedback on the outliers to improve predictor accuracy.\n",
    "\n",
    "\n",
    "The first step is to update your boto3 installation to the latest version which has the new L4M API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the new Amazon Lookout for Metrics and to establish a connection to AWS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = \"us-west-2\"\n",
    "session = boto3.Session(region_name = region)\n",
    "\n",
    "# FIXME : Beta endpoint\n",
    "L4M = session.client( \"lookoutmetrics\", endpoint_url='https://lookoutmetrics-beta.us-west-2.amazonaws.com/' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, validate that you are receiving anything back from this API call below, if you get a 200 code it means you are whitelisted and connecting to the service successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.list_metric_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Detector\n",
    "\n",
    "Now the basic external resources are ready, so it is time to get started with Amazon Lookout for Metrics, that starts with creating a `Detector`.\n",
    "\n",
    "### Detectors\n",
    "\n",
    "To detect outliers, Amazon Lookout for Metrics builds a machine learning model that is trained with your source data. This model, called a `detector`, is automatically trained with the machine learning algorithm that best fits your data and use case. You can either provide your historical data for training, if you have any, or get started with real-time data, and Amazon Lookout for Metrics will learn on-the-go. \n",
    "\n",
    "You specify the Amazon S3 location that Amazon Lookout for Metrics should continuously monitor for new data, and your detector analyzes your data and returns information about the outliers that it detected. When you create a `detector`, you also specify a `detecting domain` and an `outlier detection frequency`. \n",
    "\n",
    "The `anomaly detection frequency` specifies how frequently the detector should wake-up and look for new data, run analysis and alert you with any interesting findings.\n",
    "\n",
    "\n",
    "Execute the cells below to create a new anomaly detector with a frequency of 1 Hour. \n",
    "\n",
    "**NOTE** If you do not have an S3 bucket created for your data, go create one first then come back to these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"initial-poirot-testing-cf\" # just a string used to name resources such as MetricSet, Detector, etc.\n",
    "\n",
    "frequency = \"PT1H\" # one of 'P1D', 'PT1H', 'PT10M' and 'PT5M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_anomaly_detector( \n",
    "    AnomalyDetectorName = project + \"-detector-1\",\n",
    "    # AnomalyDetectorDomain = \"ADS\",\n",
    "    AnomalyDetectorDescription = \"My Detector\",\n",
    "    AnomalyDetectorConfig = {\n",
    "        \"AnomalyDetectorFrequency\" : frequency,\n",
    "    },\n",
    ")\n",
    "\n",
    "anomaly_detector_arn = response[\"AnomalyDetectorArn\"]\n",
    "anomaly_detector_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See details of created detector and it's status (should be `INACTIVE` at this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.describe_anomaly_detector(AnomalyDetectorArn=anomaly_detector_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrics\n",
    "\n",
    "### Measures and Dimensions\n",
    "\n",
    "`Measures` are variables or key performance indicators on which customers want to detect outliers and `Dimensions` are meta-data that represent categorical information about the measures. \n",
    "\n",
    "In this E-commerce example, views and revenue are our measures and platform and marketplace are our dimensions. Customers may want to monitor their data for anomalies in number of views or revenue for every platform, marketplace, and combination of both. You can designate up to five measures and five dimensions per dataset.\n",
    "\n",
    "### Metrics \n",
    "\n",
    "\n",
    "After creating a detector, and mapping your measures and dimensions, Amazon Lookout for Metrics will analyze each combination of these measures and dimensions. For the above example, we have of 7 unique values (us, jp, de, etc.) for marketplace and 3 unique values (mobile web, mobile app, pc web) for platform for a total of 21 unique combinations. Each unique combination of measures with the dimension values (e.g. us/mobile app/revenue) is a time series `metric`. In this case, we have 21 dimensions and 2 measures for a total of 42 time-series `metrics`. \n",
    "\n",
    "Amazon Lookout for Metrics detects anomalies at the most granular level so you are able to pin-point any unexpected behavior in your data.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "Measures, dimensions and metrics map to `datasets`, which also contain the Amazon S3 locations of your source data, an IAM role that has both read and write permissions to those Amazon S3 locations, and the rate at which data should be ingested from the source location (the upload frequency and data ingestion delay).\n",
    "\n",
    "\n",
    "First, let's create a role that can work with the Amazon Lookout for Metrics service:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility as pu\n",
    "role_name = \"L4MTestRole\"\n",
    "role_arn = pu.get_or_create_iam_role(role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a metric set for our detector that point to the Live data in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_format = 's3://'+ s3_bucket + '/ecommerce/live/{{yyyyMMdd}}/{{HHmm}}'\n",
    "s3_path_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"AnomalyDetectorArn\": anomaly_detector_arn,\n",
    "    \"MetricSetName\" : project + '-metric-set-1',\n",
    "    \"MetricList\" : [\n",
    "        {\n",
    "            \"MetricName\" : \"views\",\n",
    "            \"AggregationFunction\" : \"AVG\",\n",
    "        },\n",
    "        {\n",
    "            \"MetricName\" : \"revenue\",\n",
    "            \"AggregationFunction\" : \"SUM\",\n",
    "        },\n",
    "    ],\n",
    "\n",
    "    \"DimensionList\" : [ \"platform\", \"marketplace\" ],\n",
    "\n",
    "    \"TimestampColumn\" : {\n",
    "        \"ColumnName\" : \"timestamp\",\n",
    "        \"ColumnFormat\" : \"yyyy-MM-dd HH:mm:ss\",\n",
    "    },\n",
    "\n",
    "   #\"Delay\" : 120, # seconds the detector will wait before attempting to read latest data per current time and detection frequency below\n",
    "    \"MetricSetFrequency\" : frequency,\n",
    "\n",
    "    \"MetricSource\" : {\n",
    "        \"S3SourceConfig\": {\n",
    "            \"RoleArn\" : role_arn,\n",
    "#            \"HistoricalDataPathList\": [\n",
    "#                s3_path_training_prefix,\n",
    "#            ],\n",
    "            \"TemplatedPathList\": [\n",
    "                s3_path_format,\n",
    "            ],\n",
    "\n",
    "            \"FileFormatDescriptor\" : {\n",
    "                \"CsvFormatDescriptor\" : {\n",
    "                    \"FileCompression\" : \"NONE\",\n",
    "                    \"Charset\" : \"UTF-8\",\n",
    "                    \"ContainsHeader\" : True,\n",
    "                    \"Delimiter\" : \",\",\n",
    "#                    \"HeaderList\" : [\n",
    "#                        \"platform\",\n",
    "#                        \"marketplace\",\n",
    "#                        \"timestamp\",\n",
    "#                        \"views\",\n",
    "#                        \"revenue\"\n",
    "#                    ],\n",
    "                    \"QuoteSymbol\" : '\"'\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_metric_set( ** params )\n",
    "\n",
    "metric_set_arn = response[\"MetricSetArn\"]\n",
    "metric_set_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that the metric set was created correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.describe_metric_set(MetricSetArn=metric_set_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the Detector\n",
    "\n",
    "Now that the MetricSet has been specified, we are ready to start training the detector, that's done by activating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.activate_anomaly_detector(AnomalyDetectorArn = anomaly_detector_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.wait_anomaly_detector( L4M, anomaly_detector_arn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Anomaly Alerts:\n",
    "\n",
    "Once your detector is active, you can attach alerts to it. `Alerts` are customized notifications available via the Amazon Simple Notification Service (SNS), configurable directly via the Amazon Lookout for Metrics console and SDK. These alerts notify you whenever an anomaly of a specified severity level is detected. Severity levels are a measure of the urgency or criticality of detected outliers. Alerts are meant to guide you towards relative prioritization of the outliers. Amazon Lookout for Metrics supports Critical, High, Medium, and Low thresholds. For example, you can set an alert on your detector to notify you whenever an outlier with a Medium severity level or greater is detected.\n",
    "\n",
    "\n",
    "Before we get to creating an alert, 2 additional things are needed:\n",
    "\n",
    "1. A role giving Poirot access to SNS\n",
    "2. An SNS topic to deliver the alerts to\n",
    "\n",
    "The cells below will guide you through creating those and then it is time to create the alert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "role_name = \"L4M-SNSFullAccessCF\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"lookoutmetrics.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# Now add SNS support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSNSFullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the SNS topic for the alerts:\n",
    "\n",
    "**UPDATE YOUR CELL NUMBER BELOW!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_client = boto3.client(\"sns\")\n",
    "topic = sns_client.create_topic(Name=\"anomalyalertsCF\")\n",
    "topic_arn = topic['TopicArn']\n",
    "\n",
    "# Change to your cell\n",
    "number = \"+15555555555\" # Change to your cell\n",
    "\n",
    "sns_client.subscribe(\n",
    "        TopicArn=topic_arn,\n",
    "        Protocol='sms',\n",
    "        Endpoint=number  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly execute the cell below to configure the alerts to notify your topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_alert(\n",
    "    Action = {\n",
    "      \"SNSConfiguration\": { \n",
    "         \"RoleArn\": role_arn,\n",
    "         \"SnsTopicArn\": topic_arn\n",
    "      }\n",
    "    },\n",
    "    AlertDescription = \"Test Alert 1\",\n",
    "    AlertName = project + \"-alert-1\",\n",
    "    AnomalyDetectorArn = anomaly_detector_arn,\n",
    "    AlertSensitivityThreshold = 50\n",
    ")\n",
    "\n",
    "alert_arn = response[\"AlertArn\"]\n",
    "alert_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier on yourself we are going to leverage the magic functions of Ipython in order to save a few variables for later.\n",
    "\n",
    "Once you have executed the cells below, move on to 2.BackTestingWithHistorical.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store project\n",
    "%store s3_bucket\n",
    "%store frequency\n",
    "%store role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
